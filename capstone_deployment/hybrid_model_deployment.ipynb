{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d19ffa31",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "d19ffa31",
     "kernelId": ""
    }
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip3 install pandas\n",
    "!pip3 install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56f1ae49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Enabling eager execution\n",
      "INFO:tensorflow:Enabling v2 tensorshape\n",
      "INFO:tensorflow:Enabling resource variables\n",
      "INFO:tensorflow:Enabling tensor equality\n",
      "INFO:tensorflow:Enabling control flow v2\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import time\n",
    "import sys\n",
    "import gc\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Embedding, Reshape, Dot, Concatenate, Dense, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "import pickle\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bad96b03",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "bad96b03",
     "kernelId": ""
    }
   },
   "source": [
    "**re-create rank_dic for the hybrid model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e8aa70a",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "3e8aa70a",
     "kernelId": ""
    }
   },
   "outputs": [],
   "source": [
    "# df_train_filtered=pd.read_pickle('df_train_filtered.pkl')\n",
    "\n",
    "# # Mean rating for all movies\n",
    "# C = df_train_filtered['Rating'].mean()\n",
    "\n",
    "# # Mean rating for all movies separately\n",
    "# R = df_train_filtered.groupby(['Movie']).mean()['Rating'].values\n",
    "\n",
    "# # Rating freqency for all movies separately\n",
    "# v = df_train_filtered.groupby(['Movie']).count()['Rating'].values\n",
    "\n",
    "# # Number of minimum votes to be considered\n",
    "# m = v.min()\n",
    "\n",
    "# # Weighted formula to compute the weighted rating\n",
    "# weighted_score = pd.DataFrame(v/(v+m)*R+m/(v+m)*C, columns=['weighted_score'])\n",
    "# weighted_score.set_index(np.sort(df_train_filtered['Movie'].unique()), inplace=True)\n",
    "# weighted_score.sort_values(by='weighted_score', ascending=False, inplace=True)\n",
    "\n",
    "# from collections import OrderedDict\n",
    "\n",
    "# rank_dic=OrderedDict()\n",
    "\n",
    "# for i in range(weighted_score.shape[0]):\n",
    "#     rank_dic[weighted_score.index[i]]=weighted_score.iloc[i,0]\n",
    "\n",
    "# del df_train_filtered, C, R, v, m, weighted_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fa6ff34",
   "metadata": {},
   "source": [
    "**save the re-created rank_dic for the hybrid model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0db402a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtered_rank_dic_list=[]\n",
    "# for key in rank_dic:\n",
    "#     filtered_rank_dic_list.append([key, rank_dic[key]])\n",
    "    \n",
    "# with open('filtered_rank_dic_list.txt', 'wb') as fp:\n",
    "#     pickle.dump(filtered_rank_dic_list, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f32009",
   "metadata": {},
   "source": [
    "**load dictionaries for the hybrid model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "36358e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('filtered_user_id_mapping_list.txt', 'rb') as fp:\n",
    "    filtered_user_id_mapping_list=pickle.load(fp)\n",
    "    \n",
    "with open('filtered_movie_id_mapping_list.txt', 'rb') as fp:\n",
    "    filtered_movie_id_mapping_list=pickle.load(fp)\n",
    "    \n",
    "with open('filtered_rank_dic_list.txt', 'rb') as fp:\n",
    "    filtered_rank_dic_list=pickle.load(fp)\n",
    "    \n",
    "with open('bert_dic_list.txt', 'rb') as fp:\n",
    "    bert_dic_list=pickle.load(fp)\n",
    "    \n",
    "\n",
    "filtered_user_id_mapping={}\n",
    "\n",
    "filtered_movie_id_mapping={}\n",
    "\n",
    "filtered_rank_dic={}\n",
    "\n",
    "bert_dic={}\n",
    "\n",
    "for ele in filtered_user_id_mapping_list:\n",
    "    filtered_user_id_mapping[ele[0]]=ele[1]\n",
    "    \n",
    "for ele in filtered_movie_id_mapping_list:\n",
    "    filtered_movie_id_mapping[ele[0]]=ele[1]\n",
    "    \n",
    "for ele in filtered_rank_dic_list:\n",
    "    filtered_rank_dic[ele[0]]=ele[1]\n",
    "    \n",
    "for ele in bert_dic_list:\n",
    "    bert_dic[ele[0]]=ele[1]\n",
    "    \n",
    "del filtered_user_id_mapping_list, filtered_movie_id_mapping_list, filtered_rank_dic_list, bert_dic_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d07c14f2",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "d07c14f2",
     "kernelId": ""
    }
   },
   "source": [
    "**load models**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e08991f1",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "e08991f1",
     "kernelId": ""
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-13 21:55:06.530572: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "hybrid_model = tf.keras.models.load_model('./hybrid.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b09e2a80",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "b09e2a80",
     "kernelId": ""
    }
   },
   "source": [
    "**define a function that makes prediction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8f1b5953",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "8f1b5953",
     "kernelId": ""
    }
   },
   "outputs": [],
   "source": [
    "def hybrid_pred(user_id, movie_id, filtered_user_id_mapping,\\\n",
    "              filtered_movie_id_mapping, filtered_rank_dic, hybrid_model):\n",
    "\n",
    "    user=filtered_user_id_mapping[user_id]  \n",
    "    movie=filtered_movie_id_mapping[movie_id]\n",
    "    overview=bert_dic[movie_id]\n",
    "    pred=hybrid_model.predict([np.array([user]), np.array([movie])\\\n",
    "                       ,np.array([overview])\\\n",
    "                       ])[0,0]+filtered_rank_dic[movie_id]\n",
    "    \n",
    "    if pred<1: pred=1\n",
    "    elif pred>5: pred=5\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4569a62b",
   "metadata": {},
   "source": [
    "**try to make a prediction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4eaa23e5",
   "metadata": {
    "gradient": {
     "id": "4eaa23e5",
     "kernelId": ""
    }
   },
   "outputs": [],
   "source": [
    "hybrid_users=list(filtered_user_id_mapping.keys())\n",
    "hybrid_movies=list(filtered_movie_id_mapping.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "89dcf7d6",
   "metadata": {
    "gradient": {
     "id": "89dcf7d6",
     "kernelId": ""
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-13 21:55:07.362452: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1.6041499213309378, 2.300797505769262)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_id=hybrid_users[1130]\n",
    "movie_id=hybrid_movies[1701]\n",
    "hybrid_pred(user_id, movie_id, filtered_user_id_mapping, filtered_movie_id_mapping,\\\n",
    "            filtered_rank_dic, hybrid_model),\\\n",
    "filtered_rank_dic[movie_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "420fb4fa",
   "metadata": {
    "gradient": {
     "id": "420fb4fa",
     "kernelId": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "<tensorflow.python.keras.engine.input_layer.InputLayer object at 0x7f8cf763a430>\n",
      "True\n",
      "1\n",
      "<tensorflow.python.keras.engine.input_layer.InputLayer object at 0x7f8cf77c5700>\n",
      "True\n",
      "2\n",
      "<tensorflow.python.keras.layers.embeddings.Embedding object at 0x7f8cf77c5d60>\n",
      "True\n",
      "3\n",
      "<tensorflow.python.keras.layers.embeddings.Embedding object at 0x7f8cf77d77c0>\n",
      "True\n",
      "4\n",
      "<tensorflow.python.keras.layers.embeddings.Embedding object at 0x7f8cf77d70d0>\n",
      "True\n",
      "5\n",
      "<tensorflow.python.keras.engine.input_layer.InputLayer object at 0x7f8cf77d7910>\n",
      "True\n",
      "6\n",
      "<tensorflow.python.keras.layers.core.Reshape object at 0x7f8cf77d7e80>\n",
      "True\n",
      "7\n",
      "<tensorflow.python.keras.layers.core.Reshape object at 0x7f8cf77d7c40>\n",
      "True\n",
      "8\n",
      "<tensorflow.python.keras.layers.core.Reshape object at 0x7f8cef710d00>\n",
      "True\n",
      "9\n",
      "<tensorflow.python.keras.layers.core.Dense object at 0x7f8cf763a460>\n",
      "True\n",
      "10\n",
      "<tensorflow.python.keras.layers.merge.Dot object at 0x7f8cf77d7c10>\n",
      "True\n",
      "11\n",
      "<tensorflow.python.keras.layers.merge.Dot object at 0x7f8ce74a00d0>\n",
      "True\n",
      "12\n",
      "<tensorflow.python.keras.layers.merge.Concatenate object at 0x7f8ce74a02e0>\n",
      "True\n",
      "13\n",
      "<tensorflow.python.keras.layers.core.Dense object at 0x7f8ce74a04c0>\n",
      "True\n",
      "14\n",
      "<tensorflow.python.keras.layers.core.Dense object at 0x7f8ce74a0a30>\n",
      "True\n",
      "15\n",
      "<tensorflow.python.keras.layers.core.Dense object at 0x7f8ce74a0dc0>\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "layers=hybrid_model.layers\n",
    "for i in range(len(layers)):\n",
    "    print(i)\n",
    "    print(layers[i])\n",
    "    print(layers[i].trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b9b429c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "user (InputLayer)               [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "movie (InputLayer)              [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 1, 128)       19244160    user[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, 1, 128)       542592      movie[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 1, 128)       19244160    user[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "bert (InputLayer)               [(None, 768)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "reshape (Reshape)               (None, 128)          0           embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_2 (Reshape)             (None, 128)          0           embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 128)          0           embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 128)          98432       bert[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "dot (Dot)                       (None, 1)            0           reshape[0][0]                    \n",
      "                                                                 reshape_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dot_1 (Dot)                     (None, 1)            0           reshape_1[0][0]                  \n",
      "                                                                 dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 2)            0           dot[0][0]                        \n",
      "                                                                 dot_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 10)           30          concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 10)           110         dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 1)            11          dense_2[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 39,129,495\n",
      "Trainable params: 39,129,495\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "hybrid_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3f255fd",
   "metadata": {},
   "source": [
    "**freeze all the dense layers and the movie embedding layer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8cccc719",
   "metadata": {},
   "outputs": [],
   "source": [
    "layers=hybrid_model.layers\n",
    "layers[3].trainable=False\n",
    "layers[9].trainable=False\n",
    "layers[13].trainable=False\n",
    "layers[14].trainable=False\n",
    "layers[15].trainable=False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "993c366c",
   "metadata": {},
   "source": [
    "**try make a movie recommendation for a user that hasn't rated any movie yet**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bf793e32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1007"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user=len(hybrid_users)+0\n",
    "\n",
    "aaa=list(filtered_rank_dic.keys())\n",
    "\n",
    "# map movie ids to movie vocabulary number\n",
    "X_bert=np.array(pd.Series(np.array(aaa)).map(bert_dic).tolist())\n",
    "# map user ids to user vocabulary number\n",
    "X_user=np.array([user for i in range(X_bert.shape[0])])\n",
    "\n",
    "Y=hybrid_model.predict([X_user, pd.Series(aaa).map(filtered_movie_id_mapping).values\\\n",
    "                 ,X_bert\\\n",
    "                ])\n",
    "Y=Y[:,0]\n",
    "Y=list(Y)\n",
    "\n",
    "pred=[]\n",
    "for iii, y in enumerate(Y):\n",
    "    pred.append([aaa[iii], y+filtered_rank_dic[aaa[iii]]])\n",
    "\n",
    "# sort by score from high to low\n",
    "pred.sort(key=lambda x : x[1], reverse=True)\n",
    "pred=np.array(pred)\n",
    "pred=pred[:,0]\n",
    "pred=list(pred)\n",
    "\n",
    "for i in range(len(pred)):\n",
    "    pred[i]=int(pred[i])\n",
    "\n",
    "tot=0\n",
    "for i in range(len(pred)):\n",
    "    if pred[i]!=aaa[i]:\n",
    "        tot+=1\n",
    "tot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1dbc8b5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4231"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user=len(hybrid_users)-1\n",
    "\n",
    "aaa=list(filtered_rank_dic.keys())\n",
    "\n",
    "# map movie ids to movie vocabulary number\n",
    "X_bert=np.array(pd.Series(np.array(aaa)).map(bert_dic).tolist())\n",
    "# map user ids to user vocabulary number\n",
    "X_user=np.array([user for i in range(X_bert.shape[0])])\n",
    "\n",
    "Y=hybrid_model.predict([X_user, pd.Series(aaa).map(filtered_movie_id_mapping).values, X_bert])\n",
    "Y=Y[:,0]\n",
    "Y=list(Y)\n",
    "\n",
    "pred=[]\n",
    "for iii, y in enumerate(Y):\n",
    "    pred.append([aaa[iii], y+filtered_rank_dic[aaa[iii]]])\n",
    "\n",
    "# sort by score from high to low\n",
    "pred.sort(key=lambda x : x[1], reverse=True)\n",
    "pred=np.array(pred)\n",
    "pred=pred[:,0]\n",
    "pred=list(pred)\n",
    "\n",
    "for i in range(len(pred)):\n",
    "    pred[i]=int(pred[i])\n",
    "\n",
    "tot=0\n",
    "for i in range(len(pred)):\n",
    "    if pred[i]!=aaa[i]:\n",
    "        tot+=1\n",
    "tot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcabfb7d",
   "metadata": {},
   "source": [
    "**as we see from the result above, for a user who hasn't rated any movie, our movie recommendation largely align with the rank_dic. The difference is assumed to be due to the fact that although we have set L2 regularization terms for the user embedding, the actual user embeddings for the last 100 users are still not perfectly zero.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ec739b1",
   "metadata": {},
   "source": [
    "**now retrain the model with a few arbitrary user-movie ratings**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7a6dab2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(hybrid_movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "97e8088f",
   "metadata": {},
   "outputs": [],
   "source": [
    "hybrid_model = tf.keras.models.load_model('./hybrid.h5')\n",
    "layers=hybrid_model.layers\n",
    "layers[3].trainable=False\n",
    "layers[9].trainable=False\n",
    "layers[13].trainable=False\n",
    "layers[14].trainable=False\n",
    "layers[15].trainable=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9b86d675",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1/1 [==============================] - 1s 1s/step - loss: 15.3202\n",
      "Epoch 2/3\n",
      "1/1 [==============================] - 0s 282ms/step - loss: 15.1087\n",
      "Epoch 3/3\n",
      "1/1 [==============================] - 0s 272ms/step - loss: 14.8241\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f8cd76d0eb0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user=len(hybrid_users)+0\n",
    "\n",
    "aaa=[7, 7**2, 7**3, 7**4, 100, 103]\n",
    "for i in range(len(aaa)):\n",
    "    aaa[i]=hybrid_movies[aaa[i]]\n",
    "    \n",
    "bbb=np.array([3,5,2,1,5,4])\n",
    "\n",
    "# map movie ids to movie vocabulary number\n",
    "X_bert=np.array(pd.Series(np.array(aaa)).map(bert_dic).tolist())\n",
    "# map user ids to user vocabulary number\n",
    "X_user=np.array([user for i in range(X_bert.shape[0])])\n",
    "\n",
    "# 3 epochs because the model was trained with 3 epochs during the training phase\n",
    "hybrid_model.fit([X_user, pd.Series(aaa).map(filtered_movie_id_mapping).values, X_bert], bbb, epochs=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07c5025c",
   "metadata": {},
   "source": [
    "**make a prediciton again for one of the last 100 users, we see that this time the recommendation is vastly different from the rank_dic**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "86fbffe4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4173"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user=len(hybrid_users)+0\n",
    "\n",
    "aaa=list(filtered_rank_dic.keys())\n",
    "\n",
    "# map movie ids to movie vocabulary number\n",
    "X_bert=np.array(pd.Series(np.array(aaa)).map(bert_dic).tolist())\n",
    "# map user ids to user vocabulary number\n",
    "X_user=np.array([user for i in range(X_bert.shape[0])])\n",
    "\n",
    "Y=hybrid_model.predict([X_user, pd.Series(aaa).map(filtered_movie_id_mapping).values\\\n",
    "                 ,X_bert\\\n",
    "                ])\n",
    "Y=Y[:,0]\n",
    "Y=list(Y)\n",
    "\n",
    "pred=[]\n",
    "for iii, y in enumerate(Y):\n",
    "    pred.append([aaa[iii], y+filtered_rank_dic[aaa[iii]]])\n",
    "\n",
    "# sort by score from high to low\n",
    "pred.sort(key=lambda x : x[1], reverse=True)\n",
    "pred=np.array(pred)\n",
    "pred=pred[:,0]\n",
    "pred=list(pred)\n",
    "\n",
    "for i in range(len(pred)):\n",
    "    pred[i]=int(pred[i])\n",
    "\n",
    "tot=0\n",
    "for i in range(len(pred)):\n",
    "    if pred[i]!=aaa[i]:\n",
    "        tot+=1\n",
    "tot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "988731f9",
   "metadata": {},
   "source": [
    "**for users that are already in the training set, let's make predictions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "11e92e86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4230"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user=len(hybrid_users)-1\n",
    "\n",
    "aaa=list(filtered_rank_dic.keys())\n",
    "\n",
    "# map movie ids to movie vocabulary number\n",
    "X_bert=np.array(pd.Series(np.array(aaa)).map(bert_dic).tolist())\n",
    "# map user ids to user vocabulary number\n",
    "X_user=np.array([user for i in range(X_bert.shape[0])])\n",
    "\n",
    "Y=hybrid_model.predict([X_user, pd.Series(aaa).map(filtered_movie_id_mapping).values, X_bert])\n",
    "Y=Y[:,0]\n",
    "Y=list(Y)\n",
    "\n",
    "pred=[]\n",
    "for iii, y in enumerate(Y):\n",
    "    pred.append([aaa[iii], y+filtered_rank_dic[aaa[iii]]])\n",
    "\n",
    "# sort by score from high to low\n",
    "pred.sort(key=lambda x : x[1], reverse=True)\n",
    "pred=np.array(pred)\n",
    "pred=pred[:,0]\n",
    "pred=list(pred)\n",
    "\n",
    "for i in range(len(pred)):\n",
    "    pred[i]=int(pred[i])\n",
    "\n",
    "tot=0\n",
    "for i in range(len(pred)):\n",
    "    if pred[i]!=aaa[i]:\n",
    "        tot+=1\n",
    "tot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e00dc80",
   "metadata": {},
   "source": [
    "**notice the result is slightly different from the one above because of the regularization of the user embeddings**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a98c2495",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n"
     ]
    }
   ],
   "source": [
    "print(19)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
