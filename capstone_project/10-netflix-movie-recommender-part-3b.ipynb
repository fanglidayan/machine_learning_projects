{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In Part 3 of this project, we build a hybrid movie recommender. For each movie, input its overview (a short description of the movie) to distilled BERT for document embedding (a 768 dimensional vector). Connect a dense layer to shrink its dimension and take the dot product of this shrunk overview embedding with a vector of user embedding to get the prediction from the content-based recommender system. Meanwhile we get a second prediction from the familiar collaborative-filtering based method. We combine these two predictions using dense layers. Eventually we evaluate the model using metrics like RMSE, MAE and MAP@K. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip3 install pandas\n",
    "!pip3 install sklearn\n",
    "!pip3 install matplotlib\n",
    "!pip3 install seaborn\n",
    "!pip3 install transformers\n",
    "!pip install ipywidgets\n",
    "!jupyter nbextension enable --py widgetsnbextension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-28T20:18:41.55424Z",
     "iopub.status.busy": "2021-12-28T20:18:41.553856Z",
     "iopub.status.idle": "2021-12-28T20:18:41.560334Z",
     "shell.execute_reply": "2021-12-28T20:18:41.559311Z",
     "shell.execute_reply.started": "2021-12-28T20:18:41.55419Z"
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import time\n",
    "import sys\n",
    "import gc\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from tensorflow.keras.layers import Input, Embedding, Reshape, Dot, Concatenate, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.models import Model\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**remove useless warnings**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-28T20:18:41.563162Z",
     "iopub.status.busy": "2021-12-28T20:18:41.562195Z",
     "iopub.status.idle": "2021-12-28T20:18:41.573949Z",
     "shell.execute_reply": "2021-12-28T20:18:41.572323Z",
     "shell.execute_reply.started": "2021-12-28T20:18:41.563124Z"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-28T20:18:41.57583Z",
     "iopub.status.busy": "2021-12-28T20:18:41.575378Z",
     "iopub.status.idle": "2021-12-28T20:18:49.669869Z",
     "shell.execute_reply": "2021-12-28T20:18:49.669134Z",
     "shell.execute_reply.started": "2021-12-28T20:18:41.575762Z"
    }
   },
   "outputs": [],
   "source": [
    "df_movie_title_filtered=pd.read_pickle('df_movie_titles_filtered.pkl')\n",
    "df_train_filtered=pd.read_pickle('df_train_filtered.pkl')\n",
    "df_val_filtered=pd.read_pickle('df_val_filtered.pkl')\n",
    "df_test_filtered=pd.read_pickle('df_test_filtered.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((58526535, 3), (79336, 3), (79463, 3))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_filtered.shape, df_val_filtered.shape, df_test_filtered.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### select a subset of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sub_users=list(df_test_filtered['User'].unique())\n",
    "# random.Random(7).shuffle(sub_users)\n",
    "# sub_users=sub_users[:1000]\n",
    "\n",
    "# df_train_filtered=df_train_filtered[df_train_filtered['User'].isin(sub_users)]\n",
    "# df_val_filtered=df_val_filtered[df_val_filtered['User'].isin(sub_users)]\n",
    "# df_test_filtered=df_test_filtered[df_test_filtered['User'].isin(sub_users)]\n",
    "# df_train_filtered.shape, df_val_filtered.shape, df_test_filtered.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## prepare tokens and masks BERT model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**create a function that makes BERT input features from overview text** <br>\n",
    "**the function is copied from: https://github.com/dipanjanS/deep_transfer_learning_nlp_dhs2019/blob/master/notebooks/6%20-%20Transformers%20-%20DistilBERT.ipynb**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-28T20:18:49.673163Z",
     "iopub.status.busy": "2021-12-28T20:18:49.672709Z",
     "iopub.status.idle": "2021-12-28T20:18:49.680437Z",
     "shell.execute_reply": "2021-12-28T20:18:49.679619Z",
     "shell.execute_reply.started": "2021-12-28T20:18:49.673123Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_bert_input_features(tokenizer, docs, max_seq_length):\n",
    "    \n",
    "    all_ids, all_masks = [], []\n",
    "    for doc in docs:\n",
    "        tokens = tokenizer.tokenize(doc)\n",
    "        if len(tokens) > max_seq_length-2:\n",
    "            tokens = tokens[0 : (max_seq_length-2)]\n",
    "        tokens = ['[CLS]'] + tokens + ['[SEP]']\n",
    "        ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "        masks = [1] * len(ids)\n",
    "        # Zero-pad up to the sequence length.\n",
    "        while len(ids) < max_seq_length:\n",
    "            ids.append(0)\n",
    "            masks.append(0)\n",
    "        all_ids.append(ids)\n",
    "        all_masks.append(masks)\n",
    "    encoded = [all_ids, all_masks]\n",
    "    \n",
    "    return encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-28T20:18:49.682341Z",
     "iopub.status.busy": "2021-12-28T20:18:49.681763Z",
     "iopub.status.idle": "2021-12-28T20:18:50.410818Z",
     "shell.execute_reply": "2021-12-28T20:18:50.410116Z",
     "shell.execute_reply.started": "2021-12-28T20:18:49.682304Z"
    }
   },
   "outputs": [],
   "source": [
    "tokenizer = transformers.DistilBertTokenizer.from_pretrained('distilbert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-28T20:18:50.41328Z",
     "iopub.status.busy": "2021-12-28T20:18:50.412873Z",
     "iopub.status.idle": "2021-12-28T20:18:50.418845Z",
     "shell.execute_reply": "2021-12-28T20:18:50.418206Z",
     "shell.execute_reply.started": "2021-12-28T20:18:50.413242Z"
    }
   },
   "outputs": [],
   "source": [
    "df_movie_title_filtered['Movie']=df_movie_title_filtered.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-28T20:18:50.420449Z",
     "iopub.status.busy": "2021-12-28T20:18:50.420189Z",
     "iopub.status.idle": "2021-12-28T20:19:03.90803Z",
     "shell.execute_reply": "2021-12-28T20:19:03.907321Z",
     "shell.execute_reply.started": "2021-12-28T20:18:50.420412Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6551/6551 [00:05<00:00, 1127.70it/s]\n"
     ]
    }
   ],
   "source": [
    "MAX_SEQ_LENGTH = 300 # slightly larger than 274\n",
    "\n",
    "feature_id_dic={}\n",
    "feature_mask_dic={}\n",
    "\n",
    "for i in tqdm(range(df_movie_title_filtered.shape[0])):\n",
    "    movie=df_movie_title_filtered.iloc[i, 3]\n",
    "    overview=df_movie_title_filtered.iloc[i, 2]\n",
    "    temp=create_bert_input_features(tokenizer, [overview], max_seq_length=MAX_SEQ_LENGTH)\n",
    "    feature_id_dic[movie] = temp[0][0]\n",
    "    feature_mask_dic[movie] = temp[1][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## use a BERT model to do paragraph embedding. We won't train this model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-28T20:19:03.909739Z",
     "iopub.status.busy": "2021-12-28T20:19:03.909295Z",
     "iopub.status.idle": "2021-12-28T20:19:05.391676Z",
     "shell.execute_reply": "2021-12-28T20:19:05.390144Z",
     "shell.execute_reply.started": "2021-12-28T20:19:03.909698Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-12 17:22:07.201009: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1050] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-12 17:22:07.209783: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1050] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-12 17:22:07.210391: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1050] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-12 17:22:07.212098: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1050] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-12 17:22:07.212684: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1050] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-12 17:22:07.213272: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1050] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-12 17:22:07.678921: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1050] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-12 17:22:07.679733: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1050] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-12 17:22:07.680471: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1050] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-12 17:22:07.681159: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 14029 MB memory:  -> device: 0, name: RTX A4000, pci bus id: 0000:00:05.0, compute capability: 8.6\n",
      "2022-01-12 17:22:07.880386: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n",
      "2022-01-12 17:22:08.849697: I tensorflow/stream_executor/cuda/cuda_blas.cc:1760] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "Some layers from the model checkpoint at distilbert-base-uncased were not used when initializing TFDistilBertModel: ['vocab_layer_norm', 'activation_13', 'vocab_projector', 'vocab_transform']\n",
      "- This IS expected if you are initializing TFDistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFDistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFDistilBertModel were initialized from the model checkpoint at distilbert-base-uncased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 300, 768)\n"
     ]
    }
   ],
   "source": [
    "inp_id = tf.keras.layers.Input(shape=(MAX_SEQ_LENGTH,), dtype='int32', name=\"bert_input_ids\")\n",
    "inp_mask = tf.keras.layers.Input(shape=(MAX_SEQ_LENGTH,), dtype='int32', name=\"bert_input_masks\")\n",
    "inputs = [inp_id, inp_mask]\n",
    "\n",
    "layer=transformers.TFDistilBertModel.from_pretrained('distilbert-base-uncased')\n",
    "layer.trainable=False\n",
    "hidden_state = layer(inputs)[0]\n",
    "print(hidden_state.shape)\n",
    "output = hidden_state[:, 0]\n",
    "\n",
    "model = Model(inputs=[inp_id, inp_mask], outputs=output)\n",
    "model.compile(loss='mse', optimizer=tf.keras.optimizers.Adam(learning_rate=3e-5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### bert_dic is the actual dictionary that maps movie ids to movie overview embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-28T20:19:05.393656Z",
     "iopub.status.busy": "2021-12-28T20:19:05.392885Z",
     "iopub.status.idle": "2021-12-28T20:24:50.177832Z",
     "shell.execute_reply": "2021-12-28T20:24:50.177127Z",
     "shell.execute_reply.started": "2021-12-28T20:19:05.393616Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-12 17:22:11.124830: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    }
   ],
   "source": [
    "bert_dic={}\n",
    "\n",
    "for movie in feature_id_dic:\n",
    "    inp_id=np.array([feature_id_dic[movie]])\n",
    "    inp_mask=np.array([feature_mask_dic[movie]])\n",
    "    bert_dic[movie]=list(model.predict([inp_id, inp_mask])[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save bert_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_dic_list=[]\n",
    "for key in list(bert_dic.keys()):\n",
    "    bert_dic_list.append([key, bert_dic[key]])\n",
    "    \n",
    "with open('bert_dic_list.txt', 'wb') as fp:\n",
    "    pickle.dump(bert_dic_list, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load bert_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('bert_dic_list.txt', 'rb') as fp:\n",
    "#     bert_dic_list=pickle.load(fp)\n",
    "\n",
    "# bert_dic={}\n",
    "    \n",
    "# for ele in bert_dic_list:\n",
    "#     bert_dic[ele[0]]=ele[1]\n",
    "\n",
    "# del bert_dic_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### take a look at a vector in bert_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.hist(bert_dic[list(bert_dic.keys())[7]]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## make sure all users in val and test sets are included in train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-28T20:24:50.18118Z",
     "iopub.status.busy": "2021-12-28T20:24:50.180914Z",
     "iopub.status.idle": "2021-12-28T20:24:54.985895Z",
     "shell.execute_reply": "2021-12-28T20:24:54.985042Z",
     "shell.execute_reply.started": "2021-12-28T20:24:50.181147Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150245, 57042, 57069)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l1=list(df_train_filtered['User'].unique())\n",
    "l2=list(df_val_filtered['User'].unique())\n",
    "l3=list(df_test_filtered['User'].unique())\n",
    "len(l1), len(l2), len(l3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-28T20:24:55.27852Z",
     "iopub.status.busy": "2021-12-28T20:24:55.2781Z",
     "iopub.status.idle": "2021-12-28T20:24:55.326031Z",
     "shell.execute_reply": "2021-12-28T20:24:55.325264Z",
     "shell.execute_reply.started": "2021-12-28T20:24:55.278481Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val no problem\n",
      "test no problem\n"
     ]
    }
   ],
   "source": [
    "check=True\n",
    "l1_dic={}\n",
    "\n",
    "for ele in l1:\n",
    "    l1_dic[ele]=True\n",
    "    \n",
    "for ele in l2:\n",
    "    if ele not in l1_dic:\n",
    "        check=False\n",
    "        break\n",
    "\n",
    "if check:\n",
    "    print('val no problem')\n",
    "else:\n",
    "    print('val error')\n",
    "    \n",
    "check=True\n",
    "for ele in l3:\n",
    "    if ele not in l1_dic:\n",
    "        check=False\n",
    "        break\n",
    "\n",
    "if check:\n",
    "    print('test no problem')\n",
    "else:\n",
    "    print('test error')\n",
    "\n",
    "del l1, l2, l3, l1_dic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## make sure all movies in val and test sets are included in train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-28T20:24:55.327596Z",
     "iopub.status.busy": "2021-12-28T20:24:55.327253Z",
     "iopub.status.idle": "2021-12-28T20:24:55.447851Z",
     "shell.execute_reply": "2021-12-28T20:24:55.447051Z",
     "shell.execute_reply.started": "2021-12-28T20:24:55.327558Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4239, 4037, 4046)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l1=list(df_train_filtered['Movie'].unique())\n",
    "l2=list(df_val_filtered['Movie'].unique())\n",
    "l3=list(df_test_filtered['Movie'].unique())\n",
    "len(l1), len(l2), len(l3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-28T20:24:55.449402Z",
     "iopub.status.busy": "2021-12-28T20:24:55.449158Z",
     "iopub.status.idle": "2021-12-28T20:24:55.458266Z",
     "shell.execute_reply": "2021-12-28T20:24:55.457206Z",
     "shell.execute_reply.started": "2021-12-28T20:24:55.449369Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val no problem\n",
      "test no problem\n"
     ]
    }
   ],
   "source": [
    "check=True\n",
    "l1_dic={}\n",
    "\n",
    "for ele in l1:\n",
    "    l1_dic[ele]=True\n",
    "    \n",
    "for ele in l2:\n",
    "    if ele not in l1_dic:\n",
    "        check=False\n",
    "        break\n",
    "\n",
    "if check:\n",
    "    print('val no problem')\n",
    "else:\n",
    "    print('val error')\n",
    "    \n",
    "check=True\n",
    "for ele in l3:\n",
    "    if ele not in l1_dic:\n",
    "        check=False\n",
    "        break\n",
    "\n",
    "if check:\n",
    "    print('test no problem')\n",
    "else:\n",
    "    print('test error')\n",
    "\n",
    "del l1, l2, l3, l1_dic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## prepare features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### user embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**user_id_mapping**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-28T20:24:55.460035Z",
     "iopub.status.busy": "2021-12-28T20:24:55.459634Z",
     "iopub.status.idle": "2021-12-28T20:25:00.453645Z",
     "shell.execute_reply": "2021-12-28T20:25:00.45291Z",
     "shell.execute_reply.started": "2021-12-28T20:24:55.459999Z"
    }
   },
   "outputs": [],
   "source": [
    "user_id_mapping = {id:i for i, id in enumerate(df_train_filtered['User'].unique())}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_id_mapping_list=[]\n",
    "for key in list(user_id_mapping.keys()):\n",
    "    user_id_mapping_list.append([key, user_id_mapping[key]])\n",
    "    \n",
    "with open('filtered_user_id_mapping_list.txt', 'wb') as fp:\n",
    "    pickle.dump(user_id_mapping_list, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**convert user_id using user_id_mapping**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-28T20:25:00.456968Z",
     "iopub.status.busy": "2021-12-28T20:25:00.454795Z",
     "iopub.status.idle": "2021-12-28T20:25:06.210483Z",
     "shell.execute_reply": "2021-12-28T20:25:06.209766Z",
     "shell.execute_reply.started": "2021-12-28T20:25:00.456934Z"
    }
   },
   "outputs": [],
   "source": [
    "train_user=df_train_filtered['User'].map(user_id_mapping).values\n",
    "val_user=df_val_filtered['User'].map(user_id_mapping).values\n",
    "test_user=df_test_filtered['User'].map(user_id_mapping).values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### movie embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**movie_id_mapping**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_id_mapping = {id:i for i, id in enumerate(df_train_filtered['Movie'].unique())}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_id_mapping_list=[]\n",
    "for key in list(movie_id_mapping.keys()):\n",
    "    movie_id_mapping_list.append([key, movie_id_mapping[key]])\n",
    "    \n",
    "with open('filtered_movie_id_mapping_list.txt', 'wb') as fp:\n",
    "    pickle.dump(movie_id_mapping_list, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**create movie id feature for movie embeddings**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_movie=df_train_filtered['Movie'].map(movie_id_mapping).values\n",
    "val_movie=df_val_filtered['Movie'].map(movie_id_mapping).values\n",
    "test_movie=df_test_filtered['Movie'].map(movie_id_mapping).values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### movie ids will later be mapped to bert [CLS] token "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_bert=df_train_filtered['Movie'].values\n",
    "val_bert=df_val_filtered['Movie'].values\n",
    "test_bert=df_test_filtered['Movie'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### again we need rank_dic which stores the average movie ratings sorted from high to low"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean rating for all movies\n",
    "C = df_train_filtered['Rating'].mean()\n",
    "\n",
    "# Mean rating for all movies separately\n",
    "R = df_train_filtered.groupby(['Movie']).mean()['Rating'].values\n",
    "\n",
    "# Rating freqency for all movies separately\n",
    "v = df_train_filtered.groupby(['Movie']).count()['Rating'].values\n",
    "\n",
    "# Number of minimum votes to be considered\n",
    "m = v.min()\n",
    "\n",
    "# Weighted formula to compute the weighted rating\n",
    "weighted_score = pd.DataFrame(v/(v+m)*R+m/(v+m)*C, columns=['weighted_score'])\n",
    "weighted_score.set_index(np.sort(df_train_filtered['Movie'].unique()), inplace=True)\n",
    "weighted_score.sort_values(by='weighted_score', ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of minimum votes: 566\n"
     ]
    }
   ],
   "source": [
    "print('number of minimum votes: {}'.format(m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "rank_dic=OrderedDict()\n",
    "\n",
    "for i in range(weighted_score.shape[0]):\n",
    "    rank_dic[weighted_score.index[i]]=weighted_score.iloc[i,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_Y=df_train_filtered['Rating'].values.copy()-df_train_filtered['Movie'].map(rank_dic).values.copy()\n",
    "val_Y=df_val_filtered['Rating'].values.copy()-df_val_filtered['Movie'].map(rank_dic).values.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### our dataset will be too large in the original form of shape=(None, 768), so we need to define a batch_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-28T20:25:18.21257Z",
     "iopub.status.busy": "2021-12-28T20:25:18.212219Z",
     "iopub.status.idle": "2021-12-28T20:25:18.221108Z",
     "shell.execute_reply": "2021-12-28T20:25:18.220421Z",
     "shell.execute_reply.started": "2021-12-28T20:25:18.212531Z"
    }
   },
   "outputs": [],
   "source": [
    "def batch_generator(X0, X1, X2, Y, batch_size): \n",
    "    number_of_batches = X0.shape[0]//batch_size\n",
    "    counter=0\n",
    "    shuffle_index = np.arange(Y.shape[0])\n",
    "    np.random.shuffle(shuffle_index)\n",
    "    while 1:\n",
    "        index_batch = shuffle_index[batch_size*counter:batch_size*(counter+1)]\n",
    "        X0_batch = X0[index_batch]\n",
    "        X1_batch = X1[index_batch]\n",
    "        X2_batch = X2[index_batch].copy() # use .copy() to prevent modifying the original data X2\n",
    "        X2_batch = np.array(pd.Series(X2_batch).map(bert_dic).tolist())\n",
    "        Y_batch = Y[index_batch]\n",
    "        counter += 1\n",
    "        yield [X0_batch, X1_batch, X2_batch], Y_batch\n",
    "        if (counter >= number_of_batches):\n",
    "            np.random.shuffle(shuffle_index)\n",
    "            counter=0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-28T20:25:18.22299Z",
     "iopub.status.busy": "2021-12-28T20:25:18.222231Z",
     "iopub.status.idle": "2021-12-28T20:25:18.261998Z",
     "shell.execute_reply": "2021-12-28T20:25:18.261363Z",
     "shell.execute_reply.started": "2021-12-28T20:25:18.222953Z"
    }
   },
   "outputs": [],
   "source": [
    "# reserve some spaces for new users, for users who haven't rated any movies, recommend weighted average\n",
    "users=len(user_id_mapping)+100\n",
    "# users=len(user_id_mapping)\n",
    "movies=len(movie_id_mapping)\n",
    "embedding_size = 128\n",
    "# regularization term for user embedding\n",
    "regu=1e-7\n",
    "# 3e-6 works well for hybrid method\n",
    "learning_rate=1e-4\n",
    "\n",
    "#################################################################################################\n",
    "\n",
    "# use Input() to create tensors for - 'user' \n",
    "user_id_input = Input(shape=(1,), name='user')\n",
    "\n",
    "# Create embedding layer for users \n",
    "user_embedding_collaborative = Embedding(output_dim=embedding_size, \n",
    "                               input_dim=users,\n",
    "                               input_length=1, \n",
    "                               embeddings_regularizer=tf.keras.regularizers.l2(regu))(user_id_input)\n",
    "\n",
    "user_vector_collaborative = Reshape([embedding_size])(user_embedding_collaborative)\n",
    "\n",
    "user_embedding_bert = Embedding(output_dim=embedding_size, \n",
    "                               input_dim=users,\n",
    "                               input_length=1, \n",
    "                               embeddings_regularizer=tf.keras.regularizers.l2(regu))(user_id_input)\n",
    "\n",
    "user_vector_bert = Reshape([embedding_size])(user_embedding_bert)\n",
    "\n",
    "#################################################################################################\n",
    "\n",
    "# use Input() to create tensors for - 'movie'\n",
    "movie_id_input = Input(shape=(1,), name='movie')\n",
    "\n",
    "# Create embedding layer for users \n",
    "movie_embedding = Embedding(output_dim=embedding_size, \n",
    "                           input_dim=movies,\n",
    "                           input_length=1, \n",
    "                           embeddings_regularizer=tf.keras.regularizers.l2(regu))(movie_id_input)\n",
    "\n",
    "movie_vector = Reshape([embedding_size])(movie_embedding)\n",
    "\n",
    "#################################################################################################\n",
    "\n",
    "inp_bert = Input(shape=(768,), name='bert')\n",
    "bert_vector = Dense(embedding_size)(inp_bert)\n",
    "# bert_vector = inp_bert\n",
    "\n",
    "#################################################################################################\n",
    "\n",
    "output1 = Dot(1, normalize=False)([user_vector_collaborative, movie_vector])\n",
    "output2 = Dot(1, normalize=False)([user_vector_bert, bert_vector])\n",
    "temp = Concatenate()([output1, output2])\n",
    "temp = Dense(10)(temp)\n",
    "temp = Dense(10)(temp)\n",
    "output = Dense(1)(temp)\n",
    "\n",
    "# output = Dot(1, normalize=False)([user_vector, movie_vector])\n",
    "# temp = Concatenate()([user_vector, movie_vector, bert_vector])\n",
    "# temp = Dense(64)(temp)\n",
    "# temp = BatchNormalization()(temp)\n",
    "# output = Dense(1)(temp)\n",
    "\n",
    "model = Model(inputs=[user_id_input, movie_id_input, inp_bert], outputs=output)\n",
    "model.compile(loss='mse', optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = keras.models.load_model('./hybrid.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-28T22:46:08.656584Z",
     "iopub.status.busy": "2021-12-28T22:46:08.656036Z",
     "iopub.status.idle": "2021-12-28T22:46:08.66101Z",
     "shell.execute_reply": "2021-12-28T22:46:08.660309Z",
     "shell.execute_reply.started": "2021-12-28T22:46:08.656546Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "14288/14288 [==============================] - 3541s 248ms/step - loss: 0.7951 - val_loss: 0.7259\n",
      "Epoch 2/100\n",
      "14288/14288 [==============================] - 3517s 246ms/step - loss: 0.6471 - val_loss: 0.6748\n",
      "Epoch 3/100\n",
      "14288/14288 [==============================] - 3511s 246ms/step - loss: 0.5655 - val_loss: 0.6713\n",
      "Epoch 4/100\n",
      "14288/14288 [==============================] - 3525s 247ms/step - loss: 0.5076 - val_loss: 0.6821\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00004: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f04a014bbe0>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size=4096\n",
    "nb_epoch=100\n",
    "steps_per_epoch=train_user.shape[0]//batch_size\n",
    "# steps_per_epoch=100\n",
    "\n",
    "\n",
    "es = tf.keras.callbacks.EarlyStopping(monitor='val_loss', \n",
    "                                      patience=1,\n",
    "                                      restore_best_weights=True,\n",
    "                                      verbose=1)\n",
    "\n",
    "model.fit_generator(generator=batch_generator(train_user, train_movie, train_bert, train_Y, batch_size),\n",
    "                    epochs=nb_epoch,\n",
    "                    callbacks=[es],\n",
    "                    validation_data=([val_user, val_movie,\\\n",
    "                                      np.array(pd.Series(val_bert).map(bert_dic).tolist())], val_Y),\n",
    "                    steps_per_epoch=steps_per_epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## save the hybrid model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('hybrid.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## compare with the collaborative-filtering based model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def batch_generator(X0, X1, Y, batch_size): \n",
    "#     number_of_batches = X0.shape[0]//batch_size\n",
    "#     counter=0\n",
    "#     shuffle_index = np.arange(Y.shape[0])\n",
    "#     np.random.shuffle(shuffle_index)\n",
    "#     while 1:\n",
    "#         index_batch = shuffle_index[batch_size*counter:batch_size*(counter+1)]\n",
    "#         X0_batch = X0[index_batch]\n",
    "#         X1_batch = X1[index_batch]\n",
    "#         Y_batch = Y[index_batch]\n",
    "#         counter += 1\n",
    "#         yield [X0_batch, X1_batch], Y_batch\n",
    "#         if (counter >= number_of_batches):\n",
    "#             np.random.shuffle(shuffle_index)\n",
    "#             counter=0\n",
    "\n",
    "# ############################################################################################       \n",
    "            \n",
    "# users=len(user_id_mapping)\n",
    "# movies=len(movie_id_mapping)\n",
    "# embedding_size = 128\n",
    "\n",
    "# # use Input() to create tensors for - 'user' and 'movie'\n",
    "# user_id_input = Input(shape=(1,), name='user')\n",
    "# movie_id_input =  Input(shape=(1,), name='movie')\n",
    "\n",
    "# # Create embedding layer for users \n",
    "# user_embedding = Embedding(output_dim=embedding_size, \n",
    "#                            input_dim=users,\n",
    "#                            input_length=1, \n",
    "#                            embeddings_regularizer=tf.keras.regularizers.l2(0.0000001),\n",
    "#                            name='user_embedding')(user_id_input)\n",
    "\n",
    "# # create embedding layer for movies \n",
    "# movie_embedding = Embedding(output_dim=embedding_size, \n",
    "#                            input_dim=movies,\n",
    "#                            input_length=1, \n",
    "#                            embeddings_regularizer=tf.keras.regularizers.l2(0.0000001),\n",
    "#                            name='movie_embedding')(movie_id_input)\n",
    "\n",
    "# user_vector = Reshape([embedding_size])(user_embedding)\n",
    "# movie_vector = Reshape([embedding_size])(movie_embedding)\n",
    "\n",
    "# output = Dot(1, normalize=False)([user_vector, movie_vector])\n",
    "\n",
    "# model = Model(inputs=[user_id_input, movie_id_input], outputs=output)\n",
    "# model.compile(loss='mse', optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4))\n",
    "\n",
    "# ############################################################################################\n",
    "\n",
    "# batch_size = 1024\n",
    "# nb_epoch = 200\n",
    "# steps_per_epoch=train_user.shape[0]//batch_size\n",
    "\n",
    "# es = tf.keras.callbacks.EarlyStopping(monitor='val_loss', \n",
    "#                                       patience=2,\n",
    "#                                       restore_best_weights=True,\n",
    "#                                       verbose=1)\n",
    "\n",
    "# model.fit_generator(generator=batch_generator(train_user, train_movie, train_Y, batch_size),\n",
    "#                     epochs=nb_epoch,\n",
    "#                     callbacks=[es],\n",
    "#                     validation_data=([val_user, val_movie], val_Y),\n",
    "#                     steps_per_epoch=steps_per_epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### define a function that makes prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-28T21:15:56.049504Z",
     "iopub.status.busy": "2021-12-28T21:15:56.049019Z",
     "iopub.status.idle": "2021-12-28T21:15:56.057307Z",
     "shell.execute_reply": "2021-12-28T21:15:56.056617Z",
     "shell.execute_reply.started": "2021-12-28T21:15:56.049465Z"
    }
   },
   "outputs": [],
   "source": [
    "def make_pred(user_id, movie_id, model, rank_dic):\n",
    "#     if type(user_id)!=type('asdf'):\n",
    "#         print('please enter a string for user id')\n",
    "#         return None\n",
    "#     if movie_id not in rank_dic:\n",
    "#         print('movie id non-existent')\n",
    "        \n",
    "#     if user_id not in user_id_mapping:\n",
    "#         user=users-1\n",
    "#     else:\n",
    "#         user=user_id_mapping[user_id]\n",
    "    user=user_id_mapping[user_id]  \n",
    "    movie=movie_id_mapping[movie_id]\n",
    "    overview=bert_dic[movie_id]\n",
    "    pred=model.predict([np.array([user]), np.array([movie])\\\n",
    "                       ,np.array([overview])\\\n",
    "                       ])[0,0]+rank_dic[movie_id]\n",
    "    \n",
    "    if pred<1: pred=1\n",
    "    elif pred>5: pred=5\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### compare predictions of the content based model and the global model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-28T23:16:32.712452Z",
     "iopub.status.busy": "2021-12-28T23:16:32.711864Z",
     "iopub.status.idle": "2021-12-28T23:16:32.762553Z",
     "shell.execute_reply": "2021-12-28T23:16:32.761898Z",
     "shell.execute_reply.started": "2021-12-28T23:16:32.712409Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4.352449652380517, 4.131101053781083)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_id=list(rank_dic.keys())[38]\n",
    "user_id=list(df_test_filtered['User'].unique())[107]\n",
    "make_pred(user_id, movie_id, model, rank_dic), rank_dic[movie_id]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MAE and RMSE evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-28T23:17:29.159946Z",
     "iopub.status.busy": "2021-12-28T23:17:29.159339Z",
     "iopub.status.idle": "2021-12-28T23:17:42.175031Z",
     "shell.execute_reply": "2021-12-28T23:17:42.173428Z",
     "shell.execute_reply.started": "2021-12-28T23:17:29.159905Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The RMSE Value for the content-based recommender: 0.8148861753668504\n",
      "The MAE Value for the content-based recommender: 0.6305443603140987\n"
     ]
    }
   ],
   "source": [
    "y_pred=model.predict([test_user, test_movie\\\n",
    "                      ,np.array(pd.Series(test_bert).map(bert_dic).tolist())\\\n",
    "                     ]).flatten()\n",
    "y_pred+=df_test_filtered['Movie'].map(rank_dic).values\n",
    "\n",
    "# clip the predicted score that's lower than 1 or larger than 5\n",
    "y_pred = np.array(list(map(lambda x: 1.0 if x < 1 else 5.0 if x > 5.0 else x, y_pred)))\n",
    "\n",
    "y_true = df_test_filtered['Rating']\n",
    "\n",
    "rmse = np.sqrt(mean_squared_error(y_true=y_true, y_pred=y_pred))\n",
    "mae = mean_absolute_error(y_true=y_true, y_pred=y_pred)\n",
    "print(\"The RMSE Value for the content-based recommender:\", rmse)\n",
    "print(\"The MAE Value for the content-based recommender:\", mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### compare that with global recommender, we can see that content-based method is better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-28T23:17:42.177143Z",
     "iopub.status.busy": "2021-12-28T23:17:42.176737Z",
     "iopub.status.idle": "2021-12-28T23:17:42.191646Z",
     "shell.execute_reply": "2021-12-28T23:17:42.190764Z",
     "shell.execute_reply.started": "2021-12-28T23:17:42.177103Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The RMSE Value for the global rated average recommender: 0.9843372810325114\n",
      "The MAE Value for the global rated average recommender: 0.7928546636984719\n"
     ]
    }
   ],
   "source": [
    "y_pred = df_test_filtered['Movie'].map(rank_dic).values\n",
    "rmse = np.sqrt(mean_squared_error(y_true=y_true, y_pred=y_pred))\n",
    "mae = mean_absolute_error(y_true=y_true, y_pred=y_pred)\n",
    "print(\"The RMSE Value for the global rated average recommender:\", rmse)\n",
    "print(\"The MAE Value for the global rated average recommender:\", mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MAP@K Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dictionary of unique users in the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_user_ids={}\n",
    "\n",
    "for ele in list(df_test_filtered['User'].unique()):\n",
    "    test_user_ids[ele]=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create dictionaries that store movie id's and the average ratings of users in the train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# {user_id: [movie_id_1, movie_id_2, ...], ...}\n",
    "train_movie_ids={}\n",
    "# {user_id: average_rating, ...}\n",
    "train_movie_average_ratings={}\n",
    "ct=0\n",
    "\n",
    "for i in range(df_train_filtered.shape[0]):\n",
    "    if i % (df_train_filtered.shape[0]//100)==0: \n",
    "        # print(str(ct)+' percent of job done')\n",
    "        ct+=1\n",
    "        \n",
    "    user = df_train_filtered.iloc[i, 0]\n",
    "    if user in test_user_ids:\n",
    "        try:\n",
    "            train_movie_ids[user].append(df_train_filtered.iloc[i,2])\n",
    "            train_movie_average_ratings[user]+=df_train_filtered.iloc[i,1]\n",
    "        except:\n",
    "            train_movie_ids[user]=[df_train_filtered.iloc[i,2]]\n",
    "            train_movie_average_ratings[user]=df_train_filtered.iloc[i,1]\n",
    "\n",
    "for key in test_user_ids:\n",
    "    train_movie_average_ratings[key]/=len(train_movie_ids[key])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test_movie_ids is a dicitionary that stores positively rated movies in the test sets for each user in the test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# {user_id: [movie_id_1, movie_id_2, ...], ...}\n",
    "test_movie_ids={}\n",
    "\n",
    "for i in range(df_test_filtered.shape[0]):\n",
    "    user=df_test_filtered.iloc[i,0]\n",
    "    if df_test_filtered.iloc[i,1]>train_movie_average_ratings[user]:\n",
    "        try:\n",
    "            test_movie_ids[user].append(df_test_filtered.iloc[i,2])\n",
    "        except:\n",
    "            test_movie_ids[user]=[df_test_filtered.iloc[i,2]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save dictionaries above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_test_movie_ids_list=[]\n",
    "for key in test_movie_ids:\n",
    "    filtered_test_movie_ids_list.append([key, test_movie_ids[key]])\n",
    "    \n",
    "with open('filtered_test_movie_ids_list.txt', 'wb') as fp:\n",
    "    pickle.dump(filtered_test_movie_ids_list, fp)\n",
    "    \n",
    "############################################################\n",
    "\n",
    "filtered_train_movie_ids_list=[]\n",
    "for key in train_movie_ids:\n",
    "    filtered_train_movie_ids_list.append([key, train_movie_ids[key]])\n",
    "    \n",
    "with open('filtered_train_movie_ids_list.txt', 'wb') as fp:\n",
    "    pickle.dump(filtered_train_movie_ids_list, fp)\n",
    "    \n",
    "############################################################\n",
    "\n",
    "filtered_train_movie_average_ratings_list=[]\n",
    "for key in train_movie_average_ratings:\n",
    "    filtered_train_movie_average_ratings_list.append([key, train_movie_average_ratings[key]])\n",
    "    \n",
    "with open('filtered_train_movie_average_ratings_list.txt', 'wb') as fp:\n",
    "    pickle.dump(filtered_train_movie_average_ratings_list, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load the dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('filtered_train_movie_ids_list.txt', 'rb') as fp:\n",
    "#     train_movie_ids_list=pickle.load(fp)\n",
    "    \n",
    "# with open('filtered_train_movie_average_ratings_list.txt', 'rb') as fp:\n",
    "#     train_movie_average_ratings_list=pickle.load(fp)\n",
    "    \n",
    "# with open('filtered_test_movie_ids_list.txt', 'rb') as fp:\n",
    "#     test_movie_ids_list=pickle.load(fp)\n",
    "\n",
    "# #####################################################################    \n",
    "\n",
    "# # {user_id_1: [movie_id_1, movie_id_2, ...], ...}\n",
    "# train_movie_ids={}\n",
    "    \n",
    "# for ele in train_movie_ids_list:\n",
    "#     train_movie_ids[ele[0]]=ele[1]\n",
    "    \n",
    "# #####################################################################\n",
    "\n",
    "# train_movie_average_ratings={}\n",
    "\n",
    "# for ele in train_movie_average_ratings_list:\n",
    "#     train_movie_average_ratings[ele[0]]=ele[1]\n",
    "    \n",
    "# #####################################################################\n",
    "\n",
    "# # {user_id_1: [movie_id_3, ...], ...} \n",
    "# # the number of users in test_movie_ids is smaller than total number of users in the test set\n",
    "# # because some users in the test set give all ratings as negative (lower than average in train set)\n",
    "# test_movie_ids={}\n",
    "\n",
    "# for ele in test_movie_ids_list:\n",
    "#     test_movie_ids[ele[0]]=ele[1]\n",
    "\n",
    "# del train_movie_ids_list, train_movie_average_ratings_list, test_movie_ids_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**check the dimensions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(57069, 57069)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(train_movie_ids.keys())), len(list(df_test_filtered['User'].unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### define a function that calculates map@k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-28T21:42:27.484248Z",
     "iopub.status.busy": "2021-12-28T21:42:27.483985Z",
     "iopub.status.idle": "2021-12-28T21:42:27.489017Z",
     "shell.execute_reply": "2021-12-28T21:42:27.488351Z",
     "shell.execute_reply.started": "2021-12-28T21:42:27.484214Z"
    }
   },
   "outputs": [],
   "source": [
    "def average_precision_at_k(rel: [int], pred: [int], k: int) -> float:\n",
    "    # this function works only for a single user\n",
    "    # rel is an list of movie id's for all relevant movies in the test set \n",
    "    # pred is the prediction of the model excluding those ratings already in the training set\n",
    "    # pred is a list of movie id's whose scores are ranked from high to low\n",
    "    # len(pred) should be large enough for k\n",
    "    # k is the cutoff\n",
    "    temp=0\n",
    "    true_positive=0\n",
    "    for i in range(min(k,len(pred))):\n",
    "        if pred[i] in rel:\n",
    "            true_positive+=1\n",
    "            temp+=true_positive/(i+1)\n",
    "    return temp/len(rel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### loop through users in test set and apply the function we defined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-28T23:05:30.681796Z",
     "iopub.status.busy": "2021-12-28T23:05:30.681532Z",
     "iopub.status.idle": "2021-12-28T23:05:30.687528Z",
     "shell.execute_reply": "2021-12-28T23:05:30.686842Z",
     "shell.execute_reply.started": "2021-12-28T23:05:30.681764Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "hybrid method 0.002702702702702703\n",
      "global method  0.0008665511265164644\n",
      "1\n",
      "hybrid method 0.024630549410313972\n",
      "global method  0.015583704186061384\n",
      "2\n",
      "hybrid method 0.03051648679072313\n",
      "global method  0.016838426262910218\n",
      "3\n",
      "hybrid method 0.027662741422671566\n",
      "global method  0.016216221735840558\n",
      "4\n",
      "hybrid method 0.027515815421612987\n",
      "global method  0.019360936150991565\n",
      "5\n",
      "hybrid method 0.02844518547683355\n",
      "global method  0.018375978017756988\n",
      "6\n",
      "hybrid method 0.029639613259585022\n",
      "global method  0.017702749237732594\n",
      "7\n",
      "hybrid method 0.030935490988038834\n",
      "global method  0.0183656036718676\n",
      "8\n",
      "hybrid method 0.030954449446325482\n",
      "global method  0.0188914649345625\n",
      "9\n",
      "hybrid method 0.031645662713360556\n",
      "global method  0.01890799591212673\n",
      "10\n",
      "hybrid method 0.03133774279609866\n",
      "global method  0.018675183903417512\n",
      "11\n",
      "hybrid method 0.031589727506169965\n",
      "global method  0.018086998282742326\n",
      "12\n",
      "hybrid method 0.030785269800432502\n",
      "global method  0.018535452730713855\n",
      "13\n",
      "hybrid method 0.030901429937181413\n",
      "global method  0.018444107813988357\n",
      "14\n",
      "hybrid method 0.03138262124332008\n",
      "global method  0.017946576978478866\n",
      "15\n",
      "hybrid method 0.03209708849437114\n",
      "global method  0.01842523909026709\n",
      "16\n",
      "hybrid method 0.03186620035753136\n",
      "global method  0.018430900529690115\n",
      "17\n",
      "hybrid method 0.03150969580754724\n",
      "global method  0.018435358874018447\n",
      "18\n",
      "hybrid method 0.03154747449721758\n",
      "global method  0.018412456232492967\n",
      "19\n",
      "hybrid method 0.032004470601212205\n",
      "global method  0.018571842469005687\n",
      "20\n",
      "hybrid method 0.03207975562406452\n",
      "global method  0.018834712688380537\n",
      "21\n",
      "hybrid method 0.03230017114723544\n",
      "global method  0.018989845149301337\n",
      "22\n",
      "hybrid method 0.032038885442735254\n",
      "global method  0.019010561697421494\n",
      "23\n",
      "hybrid method 0.032186778465210196\n",
      "global method  0.01888039163795851\n",
      "24\n",
      "hybrid method 0.03202303154982584\n",
      "global method  0.018727684276461723\n",
      "25\n",
      "hybrid method 0.03181173012988422\n",
      "global method  0.01872652337175141\n",
      "26\n",
      "hybrid method 0.032065964830439636\n",
      "global method  0.01890564750549652\n",
      "27\n",
      "hybrid method 0.031999510354189666\n",
      "global method  0.018802195417054128\n",
      "28\n",
      "hybrid method 0.0320070826857206\n",
      "global method  0.018503744090500478\n",
      "29\n",
      "hybrid method 0.032095731453583014\n",
      "global method  0.01836816177750458\n",
      "30\n",
      "hybrid method 0.03231956851307093\n",
      "global method  0.018368920171956953\n",
      "31\n",
      "hybrid method 0.03257031792709637\n",
      "global method  0.01846034288268974\n",
      "32\n",
      "hybrid method 0.032437329759555225\n",
      "global method  0.01839607031812816\n",
      "33\n",
      "hybrid method 0.03251210830005574\n",
      "global method  0.01841953304238197\n",
      "34\n",
      "hybrid method 0.03255835483084682\n",
      "global method  0.01852926925042081\n",
      "35\n",
      "hybrid method 0.03257473758455788\n",
      "global method  0.01861345974350693\n",
      "36\n",
      "hybrid method 0.03267174433230733\n",
      "global method  0.01859960071285886\n",
      "37\n",
      "hybrid method 0.032555601643242664\n",
      "global method  0.018329431573679333\n",
      "38\n",
      "hybrid method 0.0324192646612424\n",
      "global method  0.01819867477122165\n",
      "39\n",
      "hybrid method 0.03227504382098555\n",
      "global method  0.0183209787669222\n",
      "40\n",
      "hybrid method 0.03225698790341284\n",
      "global method  0.018255154092880796\n",
      "41\n",
      "hybrid method 0.03229963792232865\n",
      "global method  0.018338553384395866\n",
      "42\n",
      "hybrid method 0.03237455175882133\n",
      "global method  0.01830683746024109\n",
      "43\n",
      "hybrid method 0.03216814841483787\n",
      "global method  0.018157332352309503\n",
      "44\n",
      "hybrid method 0.031996036290467676\n",
      "global method  0.018176898758779522\n",
      "45\n",
      "hybrid method 0.03197316433082752\n",
      "global method  0.018215627789323445\n",
      "46\n",
      "hybrid method 0.03199527922033577\n",
      "global method  0.018160718506383185\n",
      "47\n",
      "hybrid method 0.03194246078250516\n",
      "global method  0.01808907729546795\n",
      "48\n",
      "hybrid method 0.03206486800510671\n",
      "global method  0.018353061839054923\n",
      "49\n",
      "hybrid method 0.032068483545820155\n",
      "global method  0.018599820763478266\n",
      "50\n",
      "hybrid method 0.03200556279885379\n",
      "global method  0.018455664660478505\n",
      "51\n",
      "hybrid method 0.03205531103636645\n",
      "global method  0.018447480263491467\n",
      "52\n",
      "hybrid method 0.03194040041820929\n",
      "global method  0.018419629499297877\n",
      "53\n",
      "hybrid method 0.03200245082013738\n",
      "global method  0.018305681629339324\n",
      "54\n",
      "hybrid method 0.03184731378690568\n",
      "global method  0.01832467776006564\n",
      "55\n",
      "hybrid method 0.032036338352900054\n",
      "global method  0.01827982016687538\n",
      "56\n",
      "hybrid method 0.032021695432439164\n",
      "global method  0.01830815487984538\n",
      "57\n",
      "hybrid method 0.032082758096004305\n",
      "global method  0.018288347543917137\n",
      "58\n",
      "hybrid method 0.0320021706402724\n",
      "global method  0.01836118085644093\n",
      "59\n",
      "hybrid method 0.032088379898561295\n",
      "global method  0.01843790503625204\n",
      "60\n",
      "hybrid method 0.03205983037499513\n",
      "global method  0.018484776158109912\n",
      "61\n",
      "hybrid method 0.032295817630446866\n",
      "global method  0.018471400258641503\n",
      "62\n",
      "hybrid method 0.03242049218240855\n",
      "global method  0.018551569346754993\n",
      "63\n",
      "hybrid method 0.032401152665803054\n",
      "global method  0.018631475888405684\n",
      "64\n",
      "hybrid method 0.03237855157867589\n",
      "global method  0.018633019836304342\n",
      "65\n",
      "hybrid method 0.03238202463577204\n",
      "global method  0.018626555037697844\n",
      "66\n",
      "hybrid method 0.03236786763273216\n",
      "global method  0.018673783532670487\n",
      "67\n",
      "hybrid method 0.032507017328823565\n",
      "global method  0.018635162110320014\n",
      "68\n",
      "hybrid method 0.032510287988423585\n",
      "global method  0.018491544791096087\n",
      "69\n",
      "hybrid method 0.032523154927973905\n",
      "global method  0.018613893103661926\n",
      "70\n",
      "hybrid method 0.03258469761563369\n",
      "global method  0.01866178338253782\n",
      "71\n",
      "hybrid method 0.03259069476591471\n",
      "global method  0.01867346329540665\n",
      "72\n",
      "hybrid method 0.03263076968345526\n",
      "global method  0.018696658689338442\n",
      "73\n",
      "hybrid method 0.032599175006802386\n",
      "global method  0.018667746041563977\n",
      "74\n",
      "hybrid method 0.03259087321197435\n",
      "global method  0.018635755123978873\n",
      "75\n",
      "hybrid method 0.03243104761166213\n",
      "global method  0.018575847594924026\n",
      "76\n",
      "hybrid method 0.03243539817104455\n",
      "global method  0.018460050493046144\n",
      "77\n",
      "hybrid method 0.03247138137585518\n",
      "global method  0.01840767328749528\n",
      "78\n",
      "hybrid method 0.03238659733355237\n",
      "global method  0.01848107292166698\n",
      "79\n",
      "hybrid method 0.03239408458411523\n",
      "global method  0.018463231870509772\n",
      "80\n",
      "hybrid method 0.03238709789311631\n",
      "global method  0.018471263741452363\n",
      "81\n",
      "hybrid method 0.03231829511396586\n",
      "global method  0.018474189211636675\n",
      "82\n",
      "hybrid method 0.032302526808751834\n",
      "global method  0.018446103855632758\n",
      "83\n",
      "hybrid method 0.03215433884596445\n",
      "global method  0.01842352171601388\n",
      "84\n",
      "hybrid method 0.03210955403371776\n",
      "global method  0.018372800798052768\n",
      "85\n",
      "hybrid method 0.03202322712061806\n",
      "global method  0.01830557334891055\n",
      "86\n",
      "hybrid method 0.03199914507360508\n",
      "global method  0.018378352581888746\n",
      "87\n",
      "hybrid method 0.0319404016118408\n",
      "global method  0.01840864866583078\n",
      "88\n",
      "hybrid method 0.03179527676109353\n",
      "global method  0.018431182446308106\n",
      "89\n",
      "hybrid method 0.0316984974271512\n",
      "global method  0.018429192678163103\n",
      "90\n",
      "hybrid method 0.03172665692245615\n",
      "global method  0.01844150797480611\n",
      "91\n",
      "hybrid method 0.03176546587238354\n",
      "global method  0.018455213128163592\n",
      "92\n",
      "hybrid method 0.03166564245124777\n",
      "global method  0.018479906790586805\n",
      "93\n",
      "hybrid method 0.031697247325847805\n",
      "global method  0.018538858800962562\n",
      "94\n",
      "hybrid method 0.03171510309830581\n",
      "global method  0.018599657319480573\n",
      "95\n",
      "hybrid method 0.031692594486937405\n",
      "global method  0.018600938113614365\n",
      "96\n",
      "hybrid method 0.031693716519490794\n",
      "global method  0.018539785420501102\n",
      "97\n",
      "hybrid method 0.031709873604432\n",
      "global method  0.018537289664783147\n",
      "98\n",
      "hybrid method 0.03186248612697696\n",
      "global method  0.018592601523813874\n",
      "99\n",
      "hybrid method 0.031917663448404306\n",
      "global method  0.018569407432136736\n",
      "100\n",
      "hybrid method 0.03179916662448948\n",
      "global method  0.01860884050349157\n"
     ]
    }
   ],
   "source": [
    "result1=[]\n",
    "result2=[]\n",
    "user_list=list(test_movie_ids.keys())\n",
    "\n",
    "mile=len(user_list)//100\n",
    "ct=0\n",
    "\n",
    "for i in range(len(user_list)):\n",
    "    \n",
    "    if ct%mile==1: \n",
    "        print(ct//mile)\n",
    "        print('hybrid method', sum(result1)/len(result1))\n",
    "        print('global method ', sum(result2)/len(result2))\n",
    "    ct+=1\n",
    "\n",
    "    user=user_list[i]\n",
    "\n",
    "    rank_dic_copy=rank_dic.copy()\n",
    "\n",
    "    rel=test_movie_ids[user]\n",
    "\n",
    "    pred=[]\n",
    "    # list of movies already rated in train set\n",
    "    already=train_movie_ids[user]\n",
    "\n",
    "    # remove movies that are already in the train set\n",
    "    for ele in already:\n",
    "        rank_dic_copy.pop(ele)\n",
    "\n",
    "    # save a copy of movie ids\n",
    "    aaa=list(rank_dic_copy.keys())\n",
    "    \n",
    "    # map movie ids to movie vocabulary number\n",
    "    X_bert=np.array(pd.Series(np.array(aaa)).map(bert_dic).tolist())\n",
    "    # map user ids to user vocabulary number\n",
    "    X_user=pd.Series(np.array([user for i in range(X_bert.shape[0])])).map(user_id_mapping).values\n",
    "\n",
    "    Y=model.predict([X_user, pd.Series(aaa).map(movie_id_mapping).values\\\n",
    "                     ,X_bert\\\n",
    "                    ])\n",
    "    Y=Y[:,0]\n",
    "    Y=list(Y)\n",
    "\n",
    "    pred=[]\n",
    "    for iii, y in enumerate(Y):\n",
    "        pred.append([aaa[iii], y+rank_dic[aaa[iii]]])\n",
    "\n",
    "    # sort by score from high to low\n",
    "    pred.sort(key=lambda x : x[1], reverse=True)\n",
    "    pred=np.array(pred)\n",
    "    pred=pred[:,0]\n",
    "    pred=list(pred)\n",
    "    result1.append(average_precision_at_k(rel, pred, 100000))\n",
    "\n",
    "    result2.append(average_precision_at_k(rel, aaa, 100000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hybrid\n",
    "# 3000, 0.013, 0.016, learning rate=3e-4\n",
    "# 1000, 0.0066, 0.0075, learning rate=3e-4\n",
    "# 1000, 0.009X, 0.0075, learning rate=3e-6\n",
    "# 3000, 0.012, 0.015, learning rate=3e-6\n",
    "# collaborative\n",
    "# 1000, 0.0079, 0.0075"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-28T23:06:10.549907Z",
     "iopub.status.busy": "2021-12-28T23:06:10.548933Z",
     "iopub.status.idle": "2021-12-28T23:06:10.555412Z",
     "shell.execute_reply": "2021-12-28T23:06:10.554607Z",
     "shell.execute_reply.started": "2021-12-28T23:06:10.549857Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean average precision for hybrid method is 0.03176126849116085\n",
      "mean average precision for global method is 0.018598455323007967\n"
     ]
    }
   ],
   "source": [
    "print('mean average precision for hybrid method is {}'.format(sum(result1)/len(result1)))\n",
    "print('mean average precision for global method is {}'.format(sum(result2)/len(result2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Since we set the k->infinity in map@k, the list of average precisions should not contain zeros.** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ele in result1:\n",
    "    if ele==0: print('something is wrong')\n",
    "        \n",
    "for ele in result2:\n",
    "    if ele==0: print('something is wrong')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
