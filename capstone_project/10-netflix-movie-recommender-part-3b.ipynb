{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In Part 3 of this project, we build a content-based movie recommender. For each movie, input its overview (a short description of the movie) to distilled BERT for document embedding (a 768 dimensional vector). Learn a user-embedding whose dot product with the document embedding yields the predicted movie rating. Eventually we will evaluate the model performace by calculating RMSE, MAE and Mean Average Precision and compare the result with the global movie recommender baseline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip3 install pandas\n",
    "!pip3 install sklearn\n",
    "!pip3 install matplotlib\n",
    "!pip3 install seaborn\n",
    "!pip3 install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-28T20:18:41.55424Z",
     "iopub.status.busy": "2021-12-28T20:18:41.553856Z",
     "iopub.status.idle": "2021-12-28T20:18:41.560334Z",
     "shell.execute_reply": "2021-12-28T20:18:41.559311Z",
     "shell.execute_reply.started": "2021-12-28T20:18:41.55419Z"
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import time\n",
    "import sys\n",
    "import gc\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from tensorflow.keras.layers import Input, Embedding, Reshape, Dot, Concatenate, Dense, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**remove useless warnings**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-28T20:18:41.563162Z",
     "iopub.status.busy": "2021-12-28T20:18:41.562195Z",
     "iopub.status.idle": "2021-12-28T20:18:41.573949Z",
     "shell.execute_reply": "2021-12-28T20:18:41.572323Z",
     "shell.execute_reply.started": "2021-12-28T20:18:41.563124Z"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-28T20:18:41.57583Z",
     "iopub.status.busy": "2021-12-28T20:18:41.575378Z",
     "iopub.status.idle": "2021-12-28T20:18:49.669869Z",
     "shell.execute_reply": "2021-12-28T20:18:49.669134Z",
     "shell.execute_reply.started": "2021-12-28T20:18:41.575762Z"
    }
   },
   "outputs": [],
   "source": [
    "df_movie_title_filtered=pd.read_pickle('df_movie_titles_filtered.pkl')\n",
    "df_train_filtered=pd.read_pickle('df_train_filtered.pkl')\n",
    "df_val_filtered=pd.read_pickle('df_val_filtered.pkl')\n",
    "df_test_filtered=pd.read_pickle('df_test_filtered.pkl')\n",
    "combined_df=pd.read_pickle('combined_df.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## prepare tokens and masks BERT model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**create a function that makes BERT input features from overview text** <br>\n",
    "**the function is copied from: https://github.com/dipanjanS/deep_transfer_learning_nlp_dhs2019/blob/master/notebooks/6%20-%20Transformers%20-%20DistilBERT.ipynb**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-28T20:18:49.673163Z",
     "iopub.status.busy": "2021-12-28T20:18:49.672709Z",
     "iopub.status.idle": "2021-12-28T20:18:49.680437Z",
     "shell.execute_reply": "2021-12-28T20:18:49.679619Z",
     "shell.execute_reply.started": "2021-12-28T20:18:49.673123Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_bert_input_features(tokenizer, docs, max_seq_length):\n",
    "    \n",
    "    all_ids, all_masks = [], []\n",
    "    for doc in docs:\n",
    "        tokens = tokenizer.tokenize(doc)\n",
    "        if len(tokens) > max_seq_length-2:\n",
    "            tokens = tokens[0 : (max_seq_length-2)]\n",
    "        tokens = ['[CLS]'] + tokens + ['[SEP]']\n",
    "        ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "        masks = [1] * len(ids)\n",
    "        # Zero-pad up to the sequence length.\n",
    "        while len(ids) < max_seq_length:\n",
    "            ids.append(0)\n",
    "            masks.append(0)\n",
    "        all_ids.append(ids)\n",
    "        all_masks.append(masks)\n",
    "    encoded = [all_ids, all_masks]\n",
    "    \n",
    "    return encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install ipywidgets\n",
    "!jupyter nbextension enable --py widgetsnbextension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-28T20:18:49.682341Z",
     "iopub.status.busy": "2021-12-28T20:18:49.681763Z",
     "iopub.status.idle": "2021-12-28T20:18:50.410818Z",
     "shell.execute_reply": "2021-12-28T20:18:50.410116Z",
     "shell.execute_reply.started": "2021-12-28T20:18:49.682304Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f19fcde135d242bd96689cf14b839aad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f8ead485b184affa26214413aaf5e2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "244eb79c7d014d31b36efa310f82b1d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/455k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89374518bc8e43889f2f730e157dd5d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/483 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = transformers.DistilBertTokenizer.from_pretrained('distilbert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-28T20:18:50.41328Z",
     "iopub.status.busy": "2021-12-28T20:18:50.412873Z",
     "iopub.status.idle": "2021-12-28T20:18:50.418845Z",
     "shell.execute_reply": "2021-12-28T20:18:50.418206Z",
     "shell.execute_reply.started": "2021-12-28T20:18:50.413242Z"
    }
   },
   "outputs": [],
   "source": [
    "df_movie_title_filtered['Movie']=df_movie_title_filtered.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-28T20:18:50.420449Z",
     "iopub.status.busy": "2021-12-28T20:18:50.420189Z",
     "iopub.status.idle": "2021-12-28T20:19:03.90803Z",
     "shell.execute_reply": "2021-12-28T20:19:03.907321Z",
     "shell.execute_reply.started": "2021-12-28T20:18:50.420412Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6551/6551 [00:05<00:00, 1137.52it/s]\n"
     ]
    }
   ],
   "source": [
    "MAX_SEQ_LENGTH = 300 # slightly larger than 274\n",
    "\n",
    "feature_id_dic={}\n",
    "feature_mask_dic={}\n",
    "\n",
    "for i in tqdm(range(df_movie_title_filtered.shape[0])):\n",
    "    movie=df_movie_title_filtered.iloc[i, 3]\n",
    "    overview=df_movie_title_filtered.iloc[i, 2]\n",
    "    temp=create_bert_input_features(tokenizer, [overview], max_seq_length=MAX_SEQ_LENGTH)\n",
    "    feature_id_dic[movie] = temp[0][0]\n",
    "    feature_mask_dic[movie] = temp[1][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## use a BERT model to do paragraph embedding. We won't train this model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-28T20:19:03.909739Z",
     "iopub.status.busy": "2021-12-28T20:19:03.909295Z",
     "iopub.status.idle": "2021-12-28T20:19:05.391676Z",
     "shell.execute_reply": "2021-12-28T20:19:05.390144Z",
     "shell.execute_reply.started": "2021-12-28T20:19:03.909698Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd0bb85d8e474fb2894e82661c8ab84e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/347M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-30 14:52:48.320553: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1050] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-30 14:52:48.576819: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1050] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-30 14:52:48.577521: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1050] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-30 14:52:48.582386: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1050] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-30 14:52:48.583018: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1050] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-30 14:52:48.583557: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1050] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-30 14:52:51.142633: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1050] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-30 14:52:51.143270: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1050] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-30 14:52:51.143804: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1050] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-30 14:52:51.144889: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 14029 MB memory:  -> device: 0, name: RTX A4000, pci bus id: 0000:00:05.0, compute capability: 8.6\n",
      "2021-12-30 14:52:51.381852: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n",
      "2021-12-30 14:52:54.025115: I tensorflow/stream_executor/cuda/cuda_blas.cc:1760] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "Some layers from the model checkpoint at distilbert-base-uncased were not used when initializing TFDistilBertModel: ['vocab_projector', 'activation_13', 'vocab_layer_norm', 'vocab_transform']\n",
      "- This IS expected if you are initializing TFDistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFDistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFDistilBertModel were initialized from the model checkpoint at distilbert-base-uncased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 300, 768)\n"
     ]
    }
   ],
   "source": [
    "inp_id = tf.keras.layers.Input(shape=(MAX_SEQ_LENGTH,), dtype='int32', name=\"bert_input_ids\")\n",
    "inp_mask = tf.keras.layers.Input(shape=(MAX_SEQ_LENGTH,), dtype='int32', name=\"bert_input_masks\")\n",
    "inputs = [inp_id, inp_mask]\n",
    "\n",
    "layer=transformers.TFDistilBertModel.from_pretrained('distilbert-base-uncased')\n",
    "layer.trainable=False\n",
    "hidden_state = layer(inputs)[0]\n",
    "print(hidden_state.shape)\n",
    "output = hidden_state[:, 0]\n",
    "\n",
    "model = Model(inputs=[inp_id, inp_mask], outputs=output)\n",
    "model.compile(loss='mse', optimizer=tf.keras.optimizers.Adam(learning_rate=3e-5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**bert_dic is the actual dictionary that maps movie ids to movie overview embeddings**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-28T20:19:05.393656Z",
     "iopub.status.busy": "2021-12-28T20:19:05.392885Z",
     "iopub.status.idle": "2021-12-28T20:24:50.177832Z",
     "shell.execute_reply": "2021-12-28T20:24:50.177127Z",
     "shell.execute_reply.started": "2021-12-28T20:19:05.393616Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-30 14:52:56.482669: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    }
   ],
   "source": [
    "bert_dic={}\n",
    "\n",
    "for movie in feature_id_dic:\n",
    "    inp_id=np.array([feature_id_dic[movie]])\n",
    "    inp_mask=np.array([feature_mask_dic[movie]])\n",
    "    bert_dic[movie]=list(model.predict([inp_id, inp_mask])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_dic_list=[]\n",
    "for key in list(bert_dic.keys()):\n",
    "    bert_dic_list.append([key, bert_dic[key]])\n",
    "    \n",
    "with open('bert_dic_list.txt', 'wb') as fp:\n",
    "    pickle.dump(bert_dic_list, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**make sure all users in val and test sets are included in train set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-28T20:24:50.18118Z",
     "iopub.status.busy": "2021-12-28T20:24:50.180914Z",
     "iopub.status.idle": "2021-12-28T20:24:54.985895Z",
     "shell.execute_reply": "2021-12-28T20:24:54.985042Z",
     "shell.execute_reply.started": "2021-12-28T20:24:50.181147Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150245, 57042, 57069)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l1=list(df_train_filtered['User'].unique())\n",
    "l2=list(df_val_filtered['User'].unique())\n",
    "l3=list(df_test_filtered['User'].unique())\n",
    "len(l1), len(l2), len(l3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-28T20:24:55.27852Z",
     "iopub.status.busy": "2021-12-28T20:24:55.2781Z",
     "iopub.status.idle": "2021-12-28T20:24:55.326031Z",
     "shell.execute_reply": "2021-12-28T20:24:55.325264Z",
     "shell.execute_reply.started": "2021-12-28T20:24:55.278481Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no problem\n"
     ]
    }
   ],
   "source": [
    "check=True\n",
    "l1_dic={}\n",
    "\n",
    "for ele in l1:\n",
    "    l1_dic[ele]=True\n",
    "    \n",
    "for ele in l2:\n",
    "    if ele not in l1_dic:\n",
    "        check=False\n",
    "        break\n",
    "        \n",
    "for ele in l3:\n",
    "    if ele not in l1_dic:\n",
    "        check=False\n",
    "        break\n",
    "\n",
    "if True:\n",
    "    print('no problem')\n",
    "else:\n",
    "    print('error')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**make sure all movies in val and test sets are included in train set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-28T20:24:55.327596Z",
     "iopub.status.busy": "2021-12-28T20:24:55.327253Z",
     "iopub.status.idle": "2021-12-28T20:24:55.447851Z",
     "shell.execute_reply": "2021-12-28T20:24:55.447051Z",
     "shell.execute_reply.started": "2021-12-28T20:24:55.327558Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4239, 4037, 4046)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l1=list(df_train_filtered['Movie'].unique())\n",
    "l2=list(df_val_filtered['Movie'].unique())\n",
    "l3=list(df_test_filtered['Movie'].unique())\n",
    "len(l1), len(l2), len(l3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-28T20:24:55.449402Z",
     "iopub.status.busy": "2021-12-28T20:24:55.449158Z",
     "iopub.status.idle": "2021-12-28T20:24:55.458266Z",
     "shell.execute_reply": "2021-12-28T20:24:55.457206Z",
     "shell.execute_reply.started": "2021-12-28T20:24:55.449369Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no problem\n"
     ]
    }
   ],
   "source": [
    "check=True\n",
    "l1_dic={}\n",
    "\n",
    "for ele in l1:\n",
    "    l1_dic[ele]=True\n",
    "    \n",
    "for ele in l2:\n",
    "    if ele not in l1_dic:\n",
    "        check=False\n",
    "        break\n",
    "        \n",
    "for ele in l3:\n",
    "    if ele not in l1_dic:\n",
    "        check=False\n",
    "        break\n",
    "\n",
    "if True:\n",
    "    print('no problem')\n",
    "else:\n",
    "    print('error')\n",
    "\n",
    "del l1, l2, l3, l1_dic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**user_id_mapping**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-28T20:24:55.460035Z",
     "iopub.status.busy": "2021-12-28T20:24:55.459634Z",
     "iopub.status.idle": "2021-12-28T20:25:00.453645Z",
     "shell.execute_reply": "2021-12-28T20:25:00.45291Z",
     "shell.execute_reply.started": "2021-12-28T20:24:55.459999Z"
    }
   },
   "outputs": [],
   "source": [
    "user_id_mapping = {id:i for i, id in enumerate(df_train_filtered['User'].unique())}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_id_mapping_list=[]\n",
    "for key in list(user_id_mapping.keys()):\n",
    "    user_id_mapping_list.append([key, user_id_mapping[key]])\n",
    "    \n",
    "with open('filtered_user_id_mapping_list.txt', 'wb') as fp:\n",
    "    pickle.dump(user_id_mapping_list, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**convert user_id using user_id_mapping**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-28T20:25:00.456968Z",
     "iopub.status.busy": "2021-12-28T20:25:00.454795Z",
     "iopub.status.idle": "2021-12-28T20:25:06.210483Z",
     "shell.execute_reply": "2021-12-28T20:25:06.209766Z",
     "shell.execute_reply.started": "2021-12-28T20:25:00.456934Z"
    }
   },
   "outputs": [],
   "source": [
    "train_user=df_train_filtered['User'].map(user_id_mapping).values\n",
    "val_user=df_val_filtered['User'].map(user_id_mapping).values\n",
    "test_user=df_test_filtered['User'].map(user_id_mapping).values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**create movie id feature**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-28T20:25:06.211993Z",
     "iopub.status.busy": "2021-12-28T20:25:06.211743Z",
     "iopub.status.idle": "2021-12-28T20:25:06.216527Z",
     "shell.execute_reply": "2021-12-28T20:25:06.21587Z",
     "shell.execute_reply.started": "2021-12-28T20:25:06.211959Z"
    }
   },
   "outputs": [],
   "source": [
    "train_movie=df_train_filtered['Movie'].values\n",
    "val_movie=df_val_filtered['Movie'].values\n",
    "test_movie=df_test_filtered['Movie'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**again we need rank_dic which stores the weighted average movie ratings sorted from high to low**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "temp=combined_df.reset_index()[['Id','weighted score']].sort_values('weighted score', ascending=False)\n",
    "\n",
    "# {movie_id: weighted_score, ....}\n",
    "rank_dic=OrderedDict()\n",
    "for i in range(temp.shape[0]):\n",
    "    rank_dic[temp.iloc[i,0]]=temp.iloc[i,1]\n",
    "    \n",
    "# filter the movies that don't have overview from rank_dic\n",
    "temp=list(df_train_filtered['Movie'].unique())\n",
    "for movie in list(rank_dic.keys()):\n",
    "    if movie not in temp:\n",
    "        rank_dic.pop(movie)\n",
    "\n",
    "del temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**create labels**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-28T23:07:59.918902Z",
     "iopub.status.busy": "2021-12-28T23:07:59.918231Z",
     "iopub.status.idle": "2021-12-28T23:07:59.988603Z",
     "shell.execute_reply": "2021-12-28T23:07:59.987879Z",
     "shell.execute_reply.started": "2021-12-28T23:07:59.918861Z"
    }
   },
   "outputs": [],
   "source": [
    "train_Y=df_train_filtered['Rating'].values.copy()\n",
    "val_Y=df_val_filtered['Rating'].values.copy()\n",
    "test_Y=df_test_filtered['Rating'].values.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**subtract the weighted average score from the label**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-28T23:08:01.083628Z",
     "iopub.status.busy": "2021-12-28T23:08:01.083249Z",
     "iopub.status.idle": "2021-12-28T23:08:01.45909Z",
     "shell.execute_reply": "2021-12-28T23:08:01.458366Z",
     "shell.execute_reply.started": "2021-12-28T23:08:01.083596Z"
    }
   },
   "outputs": [],
   "source": [
    "train_Y-=df_train_filtered['Movie'].map(rank_dic).values\n",
    "val_Y-=df_val_filtered['Movie'].map(rank_dic).values\n",
    "test_Y-=df_test_filtered['Movie'].map(rank_dic).values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**our dataset will be too large in the original form of shape=(m, 768), so we need to define a batch_generator**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-28T20:25:18.21257Z",
     "iopub.status.busy": "2021-12-28T20:25:18.212219Z",
     "iopub.status.idle": "2021-12-28T20:25:18.221108Z",
     "shell.execute_reply": "2021-12-28T20:25:18.220421Z",
     "shell.execute_reply.started": "2021-12-28T20:25:18.212531Z"
    }
   },
   "outputs": [],
   "source": [
    "def batch_generator(X0, X1, Y, batch_size): \n",
    "    number_of_batches = X0.shape[0]//batch_size\n",
    "    number_of_batches = 1000\n",
    "    counter=0\n",
    "    shuffle_index = np.arange(np.shape(Y)[0])\n",
    "    np.random.shuffle(shuffle_index)\n",
    "    X0 =  X0[shuffle_index]\n",
    "    X1 =  X1[shuffle_index]\n",
    "    Y =  Y[shuffle_index]\n",
    "    while 1:\n",
    "        index_batch = shuffle_index[batch_size*counter:batch_size*(counter+1)]\n",
    "        X0_batch = X0[index_batch]\n",
    "        X1_batch = X1[index_batch]\n",
    "        X1_batch = np.array(pd.Series(X1_batch).map(bert_dic).tolist())\n",
    "        Y_batch = Y[index_batch]\n",
    "        counter += 1\n",
    "        yield [X0_batch, X1_batch], Y_batch\n",
    "        if (counter >= number_of_batches):\n",
    "            np.random.shuffle(shuffle_index)\n",
    "            counter=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-28T20:25:18.22299Z",
     "iopub.status.busy": "2021-12-28T20:25:18.222231Z",
     "iopub.status.idle": "2021-12-28T20:25:18.261998Z",
     "shell.execute_reply": "2021-12-28T20:25:18.261363Z",
     "shell.execute_reply.started": "2021-12-28T20:25:18.222953Z"
    }
   },
   "outputs": [],
   "source": [
    "# reserve some spaces for new users, for users who haven't rated any movies, recommend weighted average\n",
    "users=int(len(user_id_mapping)*1.1)\n",
    "embedding_size = 100\n",
    "\n",
    "# use Input() to create tensors for - 'user' and 'movie'\n",
    "user_id_input = Input(shape=(1,), name='user')\n",
    "\n",
    "# Create embedding layer for users \n",
    "user_embedding = Embedding(output_dim=embedding_size, \n",
    "                           input_dim=users,\n",
    "                           input_length=1, \n",
    "                           embeddings_regularizer=tf.keras.regularizers.l2(0.0001),\n",
    "                           name='user_embedding')(user_id_input)\n",
    "\n",
    "user_vector = Reshape([embedding_size])(user_embedding)\n",
    "#################################################################################################\n",
    "\n",
    "inp_bert = Input(shape=(768,), name='movie')\n",
    "movie_vector = Dense(embedding_size)(inp_bert)\n",
    "\n",
    "################################################################################################\n",
    "\n",
    "output = Dot(1, normalize=False)([user_vector, movie_vector])\n",
    "\n",
    "model = Model(inputs=[user_id_input, inp_bert], outputs=output)\n",
    "model.compile(loss='mse', optimizer=tf.keras.optimizers.Adam(learning_rate=3e-4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**map movie ids to movie overview embeddings**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-28T20:25:18.27974Z",
     "iopub.status.busy": "2021-12-28T20:25:18.279158Z",
     "iopub.status.idle": "2021-12-28T20:25:27.922059Z",
     "shell.execute_reply": "2021-12-28T20:25:27.921305Z",
     "shell.execute_reply.started": "2021-12-28T20:25:18.279681Z"
    }
   },
   "outputs": [],
   "source": [
    "val_bert=np.array(pd.Series(val_movie).map(bert_dic).tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-28T22:46:08.656584Z",
     "iopub.status.busy": "2021-12-28T22:46:08.656036Z",
     "iopub.status.idle": "2021-12-28T22:46:08.66101Z",
     "shell.execute_reply": "2021-12-28T22:46:08.660309Z",
     "shell.execute_reply.started": "2021-12-28T22:46:08.656546Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "3572/3572 [==============================] - 2981s 834ms/step - loss: 0.9073 - val_loss: 0.8442\n",
      "Epoch 2/20\n",
      "3572/3572 [==============================] - 2981s 835ms/step - loss: 0.8239 - val_loss: 0.8349\n",
      "Epoch 3/20\n",
      "3572/3572 [==============================] - 2982s 835ms/step - loss: 0.8152 - val_loss: 0.8319\n",
      "Epoch 4/20\n",
      "3572/3572 [==============================] - 2989s 837ms/step - loss: 0.8106 - val_loss: 0.8367\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00004: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f6ab53d9f70>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size=1024*16\n",
    "nb_epoch=20\n",
    "steps_per_epoch=train_user.shape[0]//batch_size\n",
    "\n",
    "\n",
    "es = tf.keras.callbacks.EarlyStopping(monitor='val_loss', \n",
    "                                      patience=1,\n",
    "                                      restore_best_weights=True,\n",
    "                                      verbose=1)\n",
    "\n",
    "model.fit_generator(generator=batch_generator(train_user, train_movie, train_Y, batch_size),\n",
    "                    epochs=nb_epoch,\n",
    "                    callbacks=[es],\n",
    "                    validation_data=([val_user, val_bert], val_Y),\n",
    "                    steps_per_epoch=steps_per_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-28T21:15:54.585529Z",
     "iopub.status.busy": "2021-12-28T21:15:54.585228Z",
     "iopub.status.idle": "2021-12-28T21:15:54.589284Z",
     "shell.execute_reply": "2021-12-28T21:15:54.588384Z",
     "shell.execute_reply.started": "2021-12-28T21:15:54.585494Z"
    }
   },
   "outputs": [],
   "source": [
    "# model = keras.models.load_model('./content_based.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-28T22:46:19.324662Z",
     "iopub.status.busy": "2021-12-28T22:46:19.323993Z",
     "iopub.status.idle": "2021-12-28T22:46:21.501373Z",
     "shell.execute_reply": "2021-12-28T22:46:21.50044Z",
     "shell.execute_reply.started": "2021-12-28T22:46:19.324623Z"
    }
   },
   "outputs": [],
   "source": [
    "model.save('content_based.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### define a function that makes prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-28T21:15:56.049504Z",
     "iopub.status.busy": "2021-12-28T21:15:56.049019Z",
     "iopub.status.idle": "2021-12-28T21:15:56.057307Z",
     "shell.execute_reply": "2021-12-28T21:15:56.056617Z",
     "shell.execute_reply.started": "2021-12-28T21:15:56.049465Z"
    }
   },
   "outputs": [],
   "source": [
    "def make_pred(user_id, movie_id, model, rank_dic):\n",
    "    if type(user_id)!=type('asdf'):\n",
    "        print('please enter a string for user id')\n",
    "        return None\n",
    "    if movie_id not in rank_dic:\n",
    "        print('movie id non-existent')\n",
    "        \n",
    "    if user_id not in user_id_mapping:\n",
    "        user=users-1\n",
    "    else:\n",
    "        user=user_id_mapping[user_id]\n",
    "        \n",
    "    movie=bert_dic[movie_id]\n",
    "    pred=model.predict([np.array([user]), np.array([movie])])[0,0]\n",
    "    pred+=rank_dic[movie_id]\n",
    "    if pred<1: pred=1\n",
    "    elif pred>5: pred=5\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**as you can see, for new users, we simply predict weighted average ratings of movies**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-28T23:14:12.608252Z",
     "iopub.status.busy": "2021-12-28T23:14:12.607685Z",
     "iopub.status.idle": "2021-12-28T23:14:12.65941Z",
     "shell.execute_reply": "2021-12-28T23:14:12.658764Z",
     "shell.execute_reply.started": "2021-12-28T23:14:12.608209Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4.473463689227797, 4.473463689227797)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_id=list(rank_dic.keys())[13]\n",
    "make_pred('asdf', movie_id, model, rank_dic), rank_dic[movie_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-28T23:16:32.712452Z",
     "iopub.status.busy": "2021-12-28T23:16:32.711864Z",
     "iopub.status.idle": "2021-12-28T23:16:32.762553Z",
     "shell.execute_reply": "2021-12-28T23:16:32.761898Z",
     "shell.execute_reply.started": "2021-12-28T23:16:32.712409Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4.652288099070288, 4.473463689227797)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_id=list(rank_dic.keys())[13]\n",
    "user_id=list(df_test_filtered['User'].unique())[7]\n",
    "make_pred(user_id, movie_id, model, rank_dic), rank_dic[movie_id]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MAE and RMSE evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-28T23:17:29.159946Z",
     "iopub.status.busy": "2021-12-28T23:17:29.159339Z",
     "iopub.status.idle": "2021-12-28T23:17:42.175031Z",
     "shell.execute_reply": "2021-12-28T23:17:42.173428Z",
     "shell.execute_reply.started": "2021-12-28T23:17:29.159905Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The RMSE Value for the content-based recommender: 0.8797305199855675\n",
      "The MAE Value for the content-based recommender: 0.6921320720882057\n"
     ]
    }
   ],
   "source": [
    "test_bert=np.array(pd.Series(test_movie).map(bert_dic).tolist())\n",
    "\n",
    "y_pred=model.predict([test_user, test_bert]).flatten()\n",
    "\n",
    "# add back the weighted score\n",
    "y_pred+=df_test_filtered['Movie'].map(rank_dic).values\n",
    "\n",
    "# clip the predicted score that's lower than 1 or larger than 5\n",
    "y_pred = np.array(list(map(lambda x: 1.0 if x < 1 else 5.0 if x > 5.0 else x, y_pred)))\n",
    "\n",
    "y_true = test_Y.copy()\n",
    "y_true+=df_test_filtered['Movie'].map(rank_dic).values\n",
    "\n",
    "rmse = np.sqrt(mean_squared_error(y_true=y_true, y_pred=y_pred))\n",
    "mae = mean_absolute_error(y_true=y_true, y_pred=y_pred)\n",
    "print(\"The RMSE Value for the content-based recommender:\", rmse)\n",
    "print(\"The MAE Value for the content-based recommender:\", mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**compare that with global recommender, we can see that content-based method is better**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-28T23:17:42.177143Z",
     "iopub.status.busy": "2021-12-28T23:17:42.176737Z",
     "iopub.status.idle": "2021-12-28T23:17:42.191646Z",
     "shell.execute_reply": "2021-12-28T23:17:42.190764Z",
     "shell.execute_reply.started": "2021-12-28T23:17:42.177103Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The RMSE Value for the global rated average recommender: 0.9849409787626872\n",
      "The MAE Value for the global rated average recommender: 0.7940365856690194\n"
     ]
    }
   ],
   "source": [
    "y_pred = df_test_filtered['Movie'].map(rank_dic).values\n",
    "rmse = np.sqrt(mean_squared_error(y_true=y_true, y_pred=y_pred))\n",
    "mae = mean_absolute_error(y_true=y_true, y_pred=y_pred)\n",
    "print(\"The RMSE Value for the global rated average recommender:\", rmse)\n",
    "print(\"The MAE Value for the global rated average recommender:\", mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MAP@K Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**list of unique users in the test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-28T21:16:09.378022Z",
     "iopub.status.busy": "2021-12-28T21:16:09.377689Z",
     "iopub.status.idle": "2021-12-28T21:16:09.405134Z",
     "shell.execute_reply": "2021-12-28T21:16:09.404343Z",
     "shell.execute_reply.started": "2021-12-28T21:16:09.377986Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57069"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_user_ids=list(df_test_filtered['User'].unique())\n",
    "\n",
    "temp={}\n",
    "for ele in test_user_ids:\n",
    "    temp[ele]=True\n",
    "test_user_ids=temp\n",
    "\n",
    "del temp\n",
    "\n",
    "len(test_user_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**create dictionaries that store movie id's and the average ratings of users in the train set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-28T21:16:09.406699Z",
     "iopub.status.busy": "2021-12-28T21:16:09.406457Z",
     "iopub.status.idle": "2021-12-28T21:42:21.742352Z",
     "shell.execute_reply": "2021-12-28T21:42:21.740912Z",
     "shell.execute_reply.started": "2021-12-28T21:16:09.406667Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 percent of job done\n",
      "1 percent of job done\n",
      "2 percent of job done\n",
      "3 percent of job done\n",
      "4 percent of job done\n",
      "5 percent of job done\n",
      "6 percent of job done\n",
      "7 percent of job done\n",
      "8 percent of job done\n",
      "9 percent of job done\n",
      "10 percent of job done\n",
      "11 percent of job done\n",
      "12 percent of job done\n",
      "13 percent of job done\n",
      "14 percent of job done\n",
      "15 percent of job done\n",
      "16 percent of job done\n",
      "17 percent of job done\n",
      "18 percent of job done\n",
      "19 percent of job done\n",
      "20 percent of job done\n",
      "21 percent of job done\n",
      "22 percent of job done\n",
      "23 percent of job done\n",
      "24 percent of job done\n",
      "25 percent of job done\n",
      "26 percent of job done\n",
      "27 percent of job done\n",
      "28 percent of job done\n",
      "29 percent of job done\n",
      "30 percent of job done\n",
      "31 percent of job done\n",
      "32 percent of job done\n",
      "33 percent of job done\n",
      "34 percent of job done\n",
      "35 percent of job done\n",
      "36 percent of job done\n",
      "37 percent of job done\n",
      "38 percent of job done\n",
      "39 percent of job done\n",
      "40 percent of job done\n",
      "41 percent of job done\n",
      "42 percent of job done\n",
      "43 percent of job done\n",
      "44 percent of job done\n",
      "45 percent of job done\n",
      "46 percent of job done\n",
      "47 percent of job done\n",
      "48 percent of job done\n",
      "49 percent of job done\n",
      "50 percent of job done\n",
      "51 percent of job done\n",
      "52 percent of job done\n",
      "53 percent of job done\n",
      "54 percent of job done\n",
      "55 percent of job done\n",
      "56 percent of job done\n",
      "57 percent of job done\n",
      "58 percent of job done\n",
      "59 percent of job done\n",
      "60 percent of job done\n",
      "61 percent of job done\n",
      "62 percent of job done\n",
      "63 percent of job done\n",
      "64 percent of job done\n",
      "65 percent of job done\n",
      "66 percent of job done\n",
      "67 percent of job done\n",
      "68 percent of job done\n",
      "69 percent of job done\n",
      "70 percent of job done\n",
      "71 percent of job done\n",
      "72 percent of job done\n",
      "73 percent of job done\n",
      "74 percent of job done\n",
      "75 percent of job done\n",
      "76 percent of job done\n",
      "77 percent of job done\n",
      "78 percent of job done\n",
      "79 percent of job done\n",
      "80 percent of job done\n",
      "81 percent of job done\n",
      "82 percent of job done\n",
      "83 percent of job done\n",
      "84 percent of job done\n",
      "85 percent of job done\n",
      "86 percent of job done\n",
      "87 percent of job done\n",
      "88 percent of job done\n",
      "89 percent of job done\n",
      "90 percent of job done\n",
      "91 percent of job done\n",
      "92 percent of job done\n",
      "93 percent of job done\n",
      "94 percent of job done\n",
      "95 percent of job done\n",
      "96 percent of job done\n",
      "97 percent of job done\n",
      "98 percent of job done\n",
      "99 percent of job done\n",
      "100 percent of job done\n"
     ]
    }
   ],
   "source": [
    "# {user_id: [movie_id_1, movie_id_2, ...], ...}\n",
    "train_movie_ids={}\n",
    "# {user_id: average_rating, ...}\n",
    "train_movie_average_ratings={}\n",
    "ct=0\n",
    "\n",
    "for i in range(df_train_filtered.shape[0]):\n",
    "    if i % (df_train_filtered.shape[0]//100)==0: \n",
    "        print(str(ct)+' percent of job done')\n",
    "        ct+=1\n",
    "        \n",
    "    user = df_train_filtered.iloc[i, 0]\n",
    "    if user in test_user_ids:\n",
    "        try:\n",
    "            train_movie_ids[user].append(df_train_filtered.iloc[i,2])\n",
    "            train_movie_average_ratings[user]+=df_train_filtered.iloc[i,1]\n",
    "        except:\n",
    "            train_movie_ids[user]=[df_train_filtered.iloc[i,2]]\n",
    "            train_movie_average_ratings[user]=df_train_filtered.iloc[i,1]\n",
    "\n",
    "del user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**divide the sum of ratings by the number of movies to get average rating for each user**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-28T21:42:21.743935Z",
     "iopub.status.busy": "2021-12-28T21:42:21.743658Z",
     "iopub.status.idle": "2021-12-28T21:42:21.813306Z",
     "shell.execute_reply": "2021-12-28T21:42:21.81265Z",
     "shell.execute_reply.started": "2021-12-28T21:42:21.743899Z"
    }
   },
   "outputs": [],
   "source": [
    "for key in test_user_ids:\n",
    "    train_movie_average_ratings[key]/=len(train_movie_ids[key])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**test_movie_ids is a dicitionary that stores positively rated movies in the test sets for each user in the test sets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-28T21:42:21.814806Z",
     "iopub.status.busy": "2021-12-28T21:42:21.814554Z",
     "iopub.status.idle": "2021-12-28T21:42:27.482709Z",
     "shell.execute_reply": "2021-12-28T21:42:27.481992Z",
     "shell.execute_reply.started": "2021-12-28T21:42:21.814772Z"
    }
   },
   "outputs": [],
   "source": [
    "# {user_id: [movie_id_1, movie_id_2, ...], ...}\n",
    "test_movie_ids={}\n",
    "\n",
    "for i in range(df_test_filtered.shape[0]):\n",
    "    user=df_test_filtered.iloc[i,0]\n",
    "    if df_test_filtered.iloc[i,1]>train_movie_average_ratings[user]:\n",
    "        try:\n",
    "            test_movie_ids[user].append(df_test_filtered.iloc[i,2])\n",
    "        except:\n",
    "            test_movie_ids[user]=[df_test_filtered.iloc[i,2]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**define a function that calculates map@k**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-28T21:42:27.484248Z",
     "iopub.status.busy": "2021-12-28T21:42:27.483985Z",
     "iopub.status.idle": "2021-12-28T21:42:27.489017Z",
     "shell.execute_reply": "2021-12-28T21:42:27.488351Z",
     "shell.execute_reply.started": "2021-12-28T21:42:27.484214Z"
    }
   },
   "outputs": [],
   "source": [
    "def average_precision_at_k(rel: [int], pred: [int], k: int) -> float:\n",
    "    # this function works only for a single user\n",
    "    # rel is an list of movie id's for all relevant movies in the test set \n",
    "    # pred is the prediction of the model excluding those ratings already in the training set\n",
    "    # pred is a list of movie id's whose scores are ranked from high to low\n",
    "    # len(pred) should be large enough for k\n",
    "    # k is the cutoff\n",
    "    temp=0\n",
    "    true_positive=0\n",
    "    for i in range(min(k,len(pred))):\n",
    "        if pred[i] in rel:\n",
    "            true_positive+=1\n",
    "            temp+=true_positive/(i+1)\n",
    "    return temp/len(rel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**loop through users in test set and apply the function we defined**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-28T23:05:30.681796Z",
     "iopub.status.busy": "2021-12-28T23:05:30.681532Z",
     "iopub.status.idle": "2021-12-28T23:05:30.687528Z",
     "shell.execute_reply": "2021-12-28T23:05:30.686842Z",
     "shell.execute_reply.started": "2021-12-28T23:05:30.681764Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "content-based method 0.0029850746268656717\n",
      "global method  0.000851063829787234\n",
      "1\n",
      "content-based method 0.017941247634556026\n",
      "global method  0.017442572183923515\n",
      "2\n",
      "content-based method 0.01621911981626531\n",
      "global method  0.018556598545060064\n",
      "3\n",
      "content-based method 0.01687817226272306\n",
      "global method  0.018372700251581824\n",
      "4\n",
      "content-based method 0.0191977682906878\n",
      "global method  0.020920093557158792\n",
      "5\n",
      "content-based method 0.019271091369626635\n",
      "global method  0.020115653498201515\n",
      "6\n",
      "content-based method 0.019335563452047563\n",
      "global method  0.019465341722946804\n",
      "7\n",
      "content-based method 0.01952718839051206\n",
      "global method  0.02014665886058497\n",
      "8\n",
      "content-based method 0.019433979096104843\n",
      "global method  0.020661304626061017\n",
      "9\n",
      "content-based method 0.01977118693688922\n",
      "global method  0.020433044029210458\n",
      "10\n",
      "content-based method 0.019453081877083653\n",
      "global method  0.020242167582991032\n",
      "11\n",
      "content-based method 0.019204173723092195\n",
      "global method  0.01964518832870463\n",
      "12\n",
      "content-based method 0.019679139970014733\n",
      "global method  0.020258533058474075\n",
      "13\n",
      "content-based method 0.01948611511161953\n",
      "global method  0.020125707342266982\n",
      "14\n",
      "content-based method 0.019177571951007204\n",
      "global method  0.01959451351267829\n",
      "15\n",
      "content-based method 0.019642878048371167\n",
      "global method  0.020128018309279107\n",
      "16\n",
      "content-based method 0.019761186962550133\n",
      "global method  0.020098841079884907\n",
      "17\n",
      "content-based method 0.019544621906049334\n",
      "global method  0.020152779474871017\n",
      "18\n",
      "content-based method 0.019373500813844192\n",
      "global method  0.020093498310346892\n",
      "19\n",
      "content-based method 0.019691407981490595\n",
      "global method  0.02026762169720232\n",
      "20\n",
      "content-based method 0.019622967653731824\n",
      "global method  0.020504812774305433\n",
      "21\n",
      "content-based method 0.019681662591027466\n",
      "global method  0.020676424606199537\n",
      "22\n",
      "content-based method 0.019676663428854792\n",
      "global method  0.020720293037765937\n",
      "23\n",
      "content-based method 0.019593528140923425\n",
      "global method  0.020573962223132417\n",
      "24\n",
      "content-based method 0.019406080167555007\n",
      "global method  0.02039052442317968\n",
      "25\n",
      "content-based method 0.019230246728842864\n",
      "global method  0.020380815036892427\n",
      "26\n",
      "content-based method 0.019244239562772176\n",
      "global method  0.020519699921438376\n",
      "27\n",
      "content-based method 0.019096044076801686\n",
      "global method  0.020417500056286172\n",
      "28\n",
      "content-based method 0.018949459833986194\n",
      "global method  0.020083475243141708\n",
      "29\n",
      "content-based method 0.018782843880218763\n",
      "global method  0.01992425236462408\n",
      "30\n",
      "content-based method 0.018703120807130064\n",
      "global method  0.01989960459146397\n",
      "31\n",
      "content-based method 0.01895007117502375\n",
      "global method  0.020048423515437088\n",
      "32\n",
      "content-based method 0.01885131815778513\n",
      "global method  0.019982362470596978\n",
      "33\n",
      "content-based method 0.018768860955123992\n",
      "global method  0.019986428518465955\n",
      "34\n",
      "content-based method 0.01885050894251304\n",
      "global method  0.020109349961952225\n",
      "35\n",
      "content-based method 0.018946211339986033\n",
      "global method  0.020202482505733366\n",
      "36\n",
      "content-based method 0.018895008282961832\n",
      "global method  0.020198201106791068\n",
      "37\n",
      "content-based method 0.01876996137802261\n",
      "global method  0.0199129295498728\n",
      "38\n",
      "content-based method 0.018695749022466526\n",
      "global method  0.019760902931439756\n",
      "39\n",
      "content-based method 0.01860405665478785\n",
      "global method  0.019902806717498896\n",
      "40\n",
      "content-based method 0.018689655049364012\n",
      "global method  0.01985284074793191\n",
      "41\n",
      "content-based method 0.018869445048437034\n",
      "global method  0.01995490270460199\n",
      "42\n",
      "content-based method 0.018800646639787384\n",
      "global method  0.019901706030137783\n",
      "43\n",
      "content-based method 0.018740071946433682\n",
      "global method  0.01974001705412633\n",
      "44\n",
      "content-based method 0.018760586815515807\n",
      "global method  0.019736008710622942\n",
      "45\n",
      "content-based method 0.018765810409622646\n",
      "global method  0.01976840460633156\n",
      "46\n",
      "content-based method 0.01869563571803776\n",
      "global method  0.019731919271836817\n",
      "47\n",
      "content-based method 0.018650148960839483\n",
      "global method  0.01965978450793496\n",
      "48\n",
      "content-based method 0.018908762045336088\n",
      "global method  0.01991464459281702\n",
      "49\n",
      "content-based method 0.01901546065384384\n",
      "global method  0.020146642175462214\n",
      "50\n",
      "content-based method 0.018922025280365056\n",
      "global method  0.019985989166660136\n",
      "51\n",
      "content-based method 0.01891840717455637\n",
      "global method  0.02003166119077595\n",
      "52\n",
      "content-based method 0.01888655886862723\n",
      "global method  0.020007096982407935\n",
      "53\n",
      "content-based method 0.018778776254758264\n",
      "global method  0.019885691957432148\n",
      "54\n",
      "content-based method 0.01881929766073259\n",
      "global method  0.01991731273244905\n",
      "55\n",
      "content-based method 0.01879562542464599\n",
      "global method  0.01987868418491363\n",
      "56\n",
      "content-based method 0.018839707825269655\n",
      "global method  0.01989359980129217\n",
      "57\n",
      "content-based method 0.018860794747720518\n",
      "global method  0.019889015206623343\n",
      "58\n",
      "content-based method 0.018751736046119002\n",
      "global method  0.019992627461060303\n",
      "59\n",
      "content-based method 0.018749786441182453\n",
      "global method  0.020059133889889877\n",
      "60\n",
      "content-based method 0.018782067691384807\n",
      "global method  0.02010297695227628\n",
      "61\n",
      "content-based method 0.018814831866941367\n",
      "global method  0.02008985716932141\n",
      "62\n",
      "content-based method 0.018868987042284645\n",
      "global method  0.02016670126339127\n",
      "63\n",
      "content-based method 0.018974106864756698\n",
      "global method  0.02025622391068745\n",
      "64\n",
      "content-based method 0.018978144003564013\n",
      "global method  0.02025589544073328\n",
      "65\n",
      "content-based method 0.019001635324130826\n",
      "global method  0.02026436847362352\n",
      "66\n",
      "content-based method 0.019193621656316866\n",
      "global method  0.020311533604717352\n",
      "67\n",
      "content-based method 0.01919753875760972\n",
      "global method  0.02025542079660268\n",
      "68\n",
      "content-based method 0.01907108669146604\n",
      "global method  0.02010475636145549\n",
      "69\n",
      "content-based method 0.019215787105531974\n",
      "global method  0.020208460980160943\n",
      "70\n",
      "content-based method 0.019203415633173803\n",
      "global method  0.020281214748716716\n",
      "71\n",
      "content-based method 0.01928651587737442\n",
      "global method  0.020332441469377727\n",
      "72\n",
      "content-based method 0.019288351954065096\n",
      "global method  0.02037200188211283\n",
      "73\n",
      "content-based method 0.019261070618521024\n",
      "global method  0.020367659857475684\n",
      "74\n",
      "content-based method 0.019226260461343805\n",
      "global method  0.020351596133863368\n",
      "75\n",
      "content-based method 0.019130741439163452\n",
      "global method  0.02028524672147917\n",
      "76\n",
      "content-based method 0.019058410050095422\n",
      "global method  0.020172607294065534\n",
      "77\n",
      "content-based method 0.01906862789368404\n",
      "global method  0.02010763847550587\n",
      "78\n",
      "content-based method 0.01904411441061747\n",
      "global method  0.02017888551342525\n",
      "79\n",
      "content-based method 0.019033128171268527\n",
      "global method  0.020160098880350842\n",
      "80\n",
      "content-based method 0.019018184684877343\n",
      "global method  0.020161760949588606\n",
      "81\n",
      "content-based method 0.01897675215063242\n",
      "global method  0.020174581420833438\n",
      "82\n",
      "content-based method 0.01892785622387683\n",
      "global method  0.020179129245960263\n",
      "83\n",
      "content-based method 0.01892269710670325\n",
      "global method  0.020170406977896158\n",
      "84\n",
      "content-based method 0.018859463469553576\n",
      "global method  0.020111576395186615\n",
      "85\n",
      "content-based method 0.01879647510273198\n",
      "global method  0.020040599005845757\n",
      "86\n",
      "content-based method 0.018909015398803453\n",
      "global method  0.020138953080527145\n",
      "87\n",
      "content-based method 0.01888492590959119\n",
      "global method  0.02018317078010177\n",
      "88\n",
      "content-based method 0.018802361944094462\n",
      "global method  0.020217779771462503\n",
      "89\n",
      "content-based method 0.018794737985837473\n",
      "global method  0.020208912274970466\n",
      "90\n",
      "content-based method 0.01877618609468087\n",
      "global method  0.020246452700118534\n",
      "91\n",
      "content-based method 0.018767432597791997\n",
      "global method  0.020263324977351303\n",
      "92\n",
      "content-based method 0.018776390656129547\n",
      "global method  0.020296568208916822\n",
      "93\n",
      "content-based method 0.01880872052722594\n",
      "global method  0.020365374259872466\n"
     ]
    }
   ],
   "source": [
    "result1=[]\n",
    "result2=[]\n",
    "user_list=list(test_movie_ids.keys())\n",
    "\n",
    "mile=len(user_list)//100\n",
    "ct=0\n",
    "\n",
    "for i in range(len(user_list)):\n",
    "    \n",
    "    if ct%mile==1: \n",
    "        print(ct//mile)\n",
    "        print('content-based method', sum(result1)/len(result1))\n",
    "        print('global method ', sum(result2)/len(result2))\n",
    "    ct+=1\n",
    "\n",
    "    user=user_list[i]\n",
    "\n",
    "    rank_dic_copy=rank_dic.copy()\n",
    "\n",
    "    rel=test_movie_ids[user]\n",
    "\n",
    "    pred=[]\n",
    "    # list of movies already rated in train set\n",
    "    already=train_movie_ids[user]\n",
    "\n",
    "    # remove movies that are already in the train set\n",
    "    for ele in already:\n",
    "        rank_dic_copy.pop(ele)\n",
    "\n",
    "    # save a copy of movie ids\n",
    "    aaa=list(rank_dic_copy.keys())\n",
    "    \n",
    "    # map movie ids to movie vocabulary number\n",
    "    X_bert=np.array(pd.Series(np.array(aaa)).map(bert_dic).tolist())\n",
    "    # map user ids to user vocabulary number\n",
    "    X_user=pd.Series(np.array([user for i in range(X_bert.shape[0])])).map(user_id_mapping).values\n",
    "\n",
    "    Y=model.predict([X_user, X_bert])\n",
    "    Y=Y[:,0]\n",
    "    Y=list(Y)\n",
    "\n",
    "    pred=[]\n",
    "    for iii, y in enumerate(Y):\n",
    "        pred.append([aaa[iii], y+rank_dic[aaa[iii]]])\n",
    "\n",
    "    # sort by score from high to low\n",
    "    pred.sort(key=lambda x : x[1], reverse=True)\n",
    "    pred=np.array(pred)\n",
    "    pred=pred[:,0]\n",
    "    pred=list(pred)\n",
    "    result1.append(average_precision_at_k(rel, pred, 100000))\n",
    "    \n",
    "    rank_dic_copy=rank_dic.copy()\n",
    "    for ele in train_movie_ids[user]:\n",
    "        rank_dic_copy.pop(ele)\n",
    "    pred=list(rank_dic_copy.keys())\n",
    "    result2.append(average_precision_at_k(rel, pred, 100000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interestingly, the mean average precision of the content-based method is comparable to the global method, although the content based method apparently has better RMSE and MAE.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-28T23:06:10.549907Z",
     "iopub.status.busy": "2021-12-28T23:06:10.548933Z",
     "iopub.status.idle": "2021-12-28T23:06:10.555412Z",
     "shell.execute_reply": "2021-12-28T23:06:10.554607Z",
     "shell.execute_reply.started": "2021-12-28T23:06:10.549857Z"
    }
   },
   "outputs": [],
   "source": [
    "print('mean average precision for content-based method is {}'.format(sum(result1)/len(result1)))\n",
    "print('mean average precision for global method is {}'.format(sum(result2)/len(result2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
